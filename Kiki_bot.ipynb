{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayleecragg/kikibot/blob/main/Kiki_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXa1uVJmUVGA"
      },
      "source": [
        "# **Setup:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nFh7jQpl4thP"
      },
      "outputs": [],
      "source": [
        "#@title Downloading JSON key from DROPBOX.\n",
        "\n",
        "!wget 'https://www.dropbox.com/scl/fi/pn62ld9lasx7pql9stchk/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TDt90Ejheu1t"
      },
      "outputs": [],
      "source": [
        "#@title Installing/upgrading gspread libraries + nodejs (essential for read/writing to Google Sheets and Scraping AO website)\n",
        "\n",
        "!pip install gspread oauth2client\n",
        "!pip install --upgrade gspread\n",
        "\n",
        "!dpkg --configure -a\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install -y ca-certificates curl gnupg\n",
        "!sudo mkdir -p /etc/apt/keyrings\n",
        "!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg\n",
        "!NODE_MAJOR=18 && echo \"deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main\" | sudo tee /etc/apt/sources.list.d/nodesource.list\n",
        "!sudo apt-get update\n",
        "!sudo dpkg --remove --force-remove-reinstreq nodejs\n",
        "!sudo dpkg --remove --force-remove-reinstreq libnode-dev\n",
        "!sudo dpkg --remove --force-remove-reinstreq libnode72:amd64\n",
        "!sudo apt-get install nodejs -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IBM8AZejUKrT"
      },
      "outputs": [],
      "source": [
        "#@title Install Puppeteer\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt install npm\n",
        "!npm install puppeteer\n",
        "!apt-get update\n",
        "!sudo apt install chromium-chromedriver\n",
        "!sudo apt update\n",
        "!sudo apt install chromium-browser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Shells:**\n"
      ],
      "metadata": {
        "id": "SAQbS8ISj1Od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Grand Slam Shells:**\n"
      ],
      "metadata": {
        "id": "sTO8tqbjgiow"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8akBQlntQQR"
      },
      "source": [
        "### **Australian Open Shells:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuLGvpqjD8YV"
      },
      "source": [
        "#### **FIRST:**\n",
        "Scraping from Australian Open website TO HTML File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KOfC2bROm2p5"
      },
      "outputs": [],
      "source": [
        "#@title Enter the URL to Scrape\n",
        "url_to_scrape = \"https://ausopen.com/schedule#!40015\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t2zGvalXUkpJ"
      },
      "outputs": [],
      "source": [
        "#@title Writing scraping instructions in index.js file\n",
        "\n",
        "%%writefile index.js\n",
        "'use strict';\n",
        "\n",
        "const puppeteer = require('puppeteer');\n",
        "const fs = require('fs');\n",
        "\n",
        "async function goPuppeteer(url) {\n",
        "  try {\n",
        "    const browser = await puppeteer.launch({\n",
        "      headless: \"new\",\n",
        "      args: ['--no-sandbox', '--disable-gpu']\n",
        "    });\n",
        "    const page = await browser.newPage();\n",
        "    await page.goto(url, {\n",
        "      waitUntil: 'load',\n",
        "      timeout: 0\n",
        "    });\n",
        "\n",
        "    const htmlContent = await page.content();\n",
        "    fs.writeFileSync('Scraped.html', htmlContent);\n",
        "    console.log(`Content saved from ${url}`);\n",
        "\n",
        "    await browser.close();\n",
        "  } catch (e) {\n",
        "    console.error(\"Error occurred:\", e);\n",
        "  }\n",
        "}\n",
        "\n",
        "// The first two elements of process.argv array are 'node' and the script name, so the third element (index 2) is the first argument.\n",
        "const url = process.argv[2];\n",
        "goPuppeteer(url);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utMQglVraM2H",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Running index.js file\n",
        "!node index.js \"$url_to_scrape\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udQ4DxpooVhd"
      },
      "source": [
        "#### **SECOND:**\n",
        "Taking data from HTML file and automating matches into shells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy3aPhbppsgn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Invoking Variables\n",
        "\n",
        "credentials_file ='/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'\n",
        "sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8'  #@param {type:\"string\"}\n",
        "template_sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8' #@param {type:\"string\"}\n",
        "template_worksheet_name = 'Australian Open'\n",
        "sheet_range = 'A1:AK1000' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dao9gTLGwCM",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Parsing data from HTML file to Google Sheets\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def extract_last_name(text):\n",
        "    \"\"\"\n",
        "    Extracts the player's last name, keeping numeric ranks and discarding non-numeric ranks.\n",
        "    \"\"\"\n",
        "    # Removing initials and splitting the text\n",
        "    cleaned_text = re.sub(r\"\\b[A-Z]\\.\\s*\", \"\", text)\n",
        "    parts = cleaned_text.split()\n",
        "\n",
        "    # Known non-numeric rank tags to exclude\n",
        "    known_non_numeric_ranks = {'Q', 'A', 'WC', 'LL'}\n",
        "\n",
        "    # Exclude known non-numeric rank tags and identify numeric rank if present\n",
        "    last_name_parts = []\n",
        "    rank = ''\n",
        "    for part in parts:\n",
        "        if part.isdigit():\n",
        "            rank = part\n",
        "        elif part not in known_non_numeric_ranks:\n",
        "            last_name_parts.append(part)\n",
        "\n",
        "    last_name = ' '.join(last_name_parts)\n",
        "\n",
        "    return last_name, rank\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "with open('Scraped.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract and format the date\n",
        "date_string = soup.select_one('.print-header__print-heading').get_text()\n",
        "extracted_date = re.search(r'\\d{1,2}\\s\\w+', date_string).group()\n",
        "date_input = datetime.strptime(extracted_date + ' 2024', '%d %B %Y').strftime('%Y-%m-%d')\n",
        "\n",
        "# Extracting the day (e.g., \"Day 1\")\n",
        "day_match = re.search(r'Day\\s\\d+', date_string)\n",
        "if day_match:\n",
        "    dest_worksheet_name = day_match.group()\n",
        "else:\n",
        "    dest_worksheet_name = 'Day Unknown'\n",
        "\n",
        "# Extracting the day number for source_worksheet_name\n",
        "day_number_match = re.search(r'Day\\s(\\d+)', date_string)\n",
        "if day_number_match:\n",
        "    day_number = day_number_match.group(1)\n",
        "    source_worksheet_name = 'Data'\n",
        "else:\n",
        "    source_worksheet_name = 'Data Unknown'\n",
        "\n",
        "# Initializing lists to store extracted data\n",
        "rounds, times, first_players, second_players, genders, courts, first_special, second_special, match_numbers = ([] for _ in range(9))\n",
        "\n",
        "match_number = 1\n",
        "\n",
        "# Extract data for each match\n",
        "for location in soup.select('.schedule-location'):\n",
        "    court_name = location.select_one('.schedule-location__location-title').get_text().strip()\n",
        "\n",
        "    for match in location.select('.score-row'):\n",
        "        # Extract round information\n",
        "        round_info = match.select_one('.score-header__subtitle')\n",
        "        rounds.append(round_info.get_text().split('•')[1].strip() if round_info else '')\n",
        "\n",
        "        # Extract time data\n",
        "        time_info = match.select_one('.schedule-location__session-text')\n",
        "        times.append(time_info.get_text().split('From')[1].strip() if time_info else '')\n",
        "\n",
        "        # Extract players and their ranks\n",
        "        player_groups = match.select('.player-row__team-wrapper')\n",
        "        if player_groups:\n",
        "            # Extract for first team\n",
        "            first_team_players = player_groups[0].select('p')\n",
        "            if len(first_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                first_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in first_team_players)\n",
        "                first_spec = ''\n",
        "            else:\n",
        "                first_names, first_spec = extract_last_name(first_team_players[0].get_text())\n",
        "\n",
        "            # Extract for second team\n",
        "            second_team_players = player_groups[1].select('p') if len(player_groups) > 1 else []\n",
        "            if len(second_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                second_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in second_team_players)\n",
        "                second_spec = ''\n",
        "            else:\n",
        "                second_names, second_spec = extract_last_name(second_team_players[0].get_text()) if second_team_players else ('', '')\n",
        "        else:\n",
        "            first_names, second_names, first_spec, second_spec = ('', '', '', '')\n",
        "\n",
        "        first_players.append(first_names)\n",
        "        second_players.append(second_names)\n",
        "        first_special.append(first_spec)\n",
        "        second_special.append(second_spec)\n",
        "\n",
        "        genders.append(round_info.get_text().split('•')[0].strip() if round_info else '')\n",
        "        courts.append(court_name)\n",
        "        match_numbers.append(match_number)\n",
        "        match_number += 1\n",
        "\n",
        "# Step 3: Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'First Player': first_players,\n",
        "    'Second Player': second_players,\n",
        "    'Round': rounds,\n",
        "    'Time': times,\n",
        "    'Gender': genders,\n",
        "    'Court': courts,\n",
        "    'Player 1 Rank': first_special,\n",
        "    'Player 2 Rank': second_special,\n",
        "    'Match Number': match_numbers\n",
        "})\n",
        "\n",
        "# Authenticate and connect to Google Sheets\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "\n",
        "# Check if the worksheet already exists, if not, create a new one\n",
        "try:\n",
        "    worksheet = sheet.worksheet(source_worksheet_name)\n",
        "except gspread.WorksheetNotFound:\n",
        "    worksheet = sheet.add_worksheet(title=source_worksheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame to a list of lists and upload to Google Sheets\n",
        "worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "worksheet.update('J1', match_number - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kd5-HuC_bglh"
      },
      "outputs": [],
      "source": [
        "#@title Parsing the existing times\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pytz  # Ensure this is installed\n",
        "from bs4 import BeautifulSoup\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "worksheet = sheet.worksheet(source_worksheet_name)\n",
        "\n",
        "total_matches_script_a = int(worksheet.acell('J1').value)\n",
        "\n",
        "\n",
        "def convert_gmt_to_local_24hr(gmt_time_str):\n",
        "    \"\"\"Converts GMT time string to GMT+11 in 24-hour format and returns it.\"\"\"\n",
        "    try:\n",
        "        gmt_time = datetime.strptime(gmt_time_str, '%I:%M%p')\n",
        "        gmt_time = pytz.timezone('GMT').localize(gmt_time)\n",
        "        local_time = gmt_time.astimezone(pytz.timezone('Etc/GMT-11'))\n",
        "        return local_time.strftime('%H:%M')  # 24-hour format\n",
        "    except ValueError:\n",
        "        return ''\n",
        "\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "html_file_path = 'Scraped.html'  # Replace with your actual file path\n",
        "with open(html_file_path, 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# List to store extracted datetimes along with match numbers\n",
        "start_datetimes_with_numbers = []\n",
        "\n",
        "# Initialize match counter before the loop\n",
        "match_number = 1\n",
        "\n",
        "# Variable to store the current session time\n",
        "current_session_time = None\n",
        "time_assigned = False  # Flag to check if time is assigned to a session\n",
        "\n",
        "# Loop through each element in the HTML\n",
        "for element in soup.find_all(True, class_=['schedule-location__session-text', 'score-row']):\n",
        "    if 'schedule-location__session-text' in element.get('class', []):\n",
        "        # Extract the session time\n",
        "        time_text = element.get_text()\n",
        "        time_match = re.search(r'(From|Not before)\\s+(\\d+:\\d+\\w+)', time_text)\n",
        "        if time_match:\n",
        "            gmt_time = time_match.group(2)\n",
        "            local_time_24hr = convert_gmt_to_local_24hr(gmt_time)\n",
        "            current_session_time = datetime.strptime(f\"{date_input} {local_time_24hr}\", \"%Y-%m-%d %H:%M\") if local_time_24hr != '' else ''\n",
        "            time_assigned = True  # Time is assigned for this session\n",
        "        else:\n",
        "            current_session_time = ''\n",
        "            time_assigned = False  # No valid time for this session\n",
        "    elif 'score-row' in element.get('class', []):\n",
        "        # Assign the current session time to the match only if the time was assigned in the current session\n",
        "        if time_assigned:\n",
        "            start_datetimes_with_numbers.append((match_number, current_session_time))\n",
        "        else:\n",
        "            start_datetimes_with_numbers.append((match_number, ''))  # Or skip this line to not include matches without times\n",
        "\n",
        "        # Increment match counter\n",
        "        match_number += 1\n",
        "        time_assigned = False  # Reset the flag after assigning time to a match\n",
        "\n",
        "# Prepare data for writing (convert datetime objects to strings)\n",
        "data_to_write = []\n",
        "for match in start_datetimes_with_numbers:\n",
        "    # Convert datetime to string, or leave as 'N/A' if not a datetime object\n",
        "    datetime_str = match[1].strftime('%Y-%m-%d %H:%M') if isinstance(match[1], datetime) else match[1]\n",
        "    data_to_write.append([datetime_str])\n",
        "# Write data to Google Sheet starting from cell B2\n",
        "worksheet.update('D2', data_to_write)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DLhrG_1yDnlP"
      },
      "outputs": [],
      "source": [
        "#@title Calculating the rest of the times\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def update_missing_match_times(sheet_id, source_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "    worksheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "\n",
        "    # Read the data from the sheet\n",
        "    try:\n",
        "        data = worksheet.get_all_values()\n",
        "        matches = data[1:]  # Assuming the first row is a header\n",
        "\n",
        "        current_court = None\n",
        "        current_time = None\n",
        "        previous_match_type = None  # Track the type of the previous match\n",
        "\n",
        "        for i, row in enumerate(matches):\n",
        "            existing_time_str = row[3]  # Time information in Column D\n",
        "            court = row[5]  # Court information in Column F\n",
        "            match_type = row[4]  # Match type in Column E\n",
        "\n",
        "            if existing_time_str.strip():\n",
        "                # If there is an existing time, parse it and use it as the current time\n",
        "                current_time = datetime.strptime(existing_time_str, '%Y-%m-%d %H:%M')\n",
        "            else:\n",
        "                # Skip if current_time is not set (i.e., no previous match time to base on)\n",
        "                if not current_time:\n",
        "                    continue\n",
        "\n",
        "                # Calculate the match time based on the gender information\n",
        "                duration = timedelta(hours=3) if previous_match_type == \"Men's Singles\" else timedelta(hours=2)\n",
        "                current_time += duration\n",
        "\n",
        "                # Format the date-time in an ISO format recognized by Google Sheets\n",
        "                iso_formatted_time = current_time.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "                # Update the sheet with new value for this row\n",
        "                worksheet.update(f'D{i + 2}', [[iso_formatted_time]])  # i + 2 to write to the correct row\n",
        "\n",
        "            # Update court and previous match type for next iteration\n",
        "            current_court = court\n",
        "            previous_match_type = match_type\n",
        "\n",
        "        # Apply the desired date format to the column\n",
        "        date_format = {\"numberFormat\": {\"type\": \"DATE_TIME\", \"pattern\": \"dd/MM/yyyy HH:mm\"}}\n",
        "        worksheet.format('B2:B' + str(len(matches) + 1), date_format)\n",
        "\n",
        "        print(\"Missing match times updated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sheet: {e}\")\n",
        "\n",
        "# Example call to the function (replace with actual values)\n",
        "update_missing_match_times(sheet_id, source_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ldi_rsOwcnEk"
      },
      "outputs": [],
      "source": [
        "#@title Setting up initial Day from template\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the source and destination Google Sheets\n",
        "    try:\n",
        "        source_sheet = client.open_by_key(template_sheet_id)\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if the destination worksheet exists, create if not\n",
        "    try:\n",
        "        dest_worksheet = None\n",
        "        try:\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create a new worksheet\n",
        "            dest_sheet.add_worksheet(title=dest_worksheet_name, rows=\"1000\", cols=\"26\")  # Adjust rows and columns as needed\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "\n",
        "        source_worksheet = source_sheet.worksheet(template_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing or creating worksheets: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the detailed data from the source sheet\n",
        "        source_range = f'{source_worksheet.title}!{sheet_range}'\n",
        "        request = service.spreadsheets().get(spreadsheetId=template_sheet_id, ranges=[source_range], includeGridData=True)\n",
        "        source_data = request.execute()\n",
        "\n",
        "        # Extract data for updating the destination sheet\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            row_data = []\n",
        "            for cell in row.get('values', []):\n",
        "                # Handle different types of values including formulas\n",
        "                if 'userEnteredValue' in cell:\n",
        "                    cell_value = cell['userEnteredValue']\n",
        "                    if 'formulaValue' in cell_value:\n",
        "                        row_data.append(cell_value['formulaValue'])\n",
        "                    elif 'stringValue' in cell_value:\n",
        "                        row_data.append(cell_value['stringValue'])\n",
        "                    elif 'numberValue' in cell_value:\n",
        "                        row_data.append(cell_value['numberValue'])\n",
        "                    elif 'boolValue' in cell_value:\n",
        "                        row_data.append(cell_value['boolValue'])\n",
        "                    else:\n",
        "                        row_data.append('')\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Extract data validation rules\n",
        "        validation_rules = []\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        for i, row in enumerate(rows):\n",
        "            for j, cell in enumerate(row.get('values', [])):\n",
        "                if 'dataValidation' in cell:\n",
        "                    rule = cell['dataValidation']\n",
        "                    validation_rules.append({\n",
        "                        'range': {\n",
        "                            'sheetId': dest_worksheet.id,\n",
        "                            'startRowIndex': i,\n",
        "                            'endRowIndex': i + 1,\n",
        "                            'startColumnIndex': j,\n",
        "                            'endColumnIndex': j + 1\n",
        "                        },\n",
        "                        'rule': rule\n",
        "                    })\n",
        "\n",
        "        # Write values and formulas to the destination sheet\n",
        "        dest_range = f'{dest_worksheet.title}!{sheet_range}'\n",
        "        body = {'values': data}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Apply data validation rules to the destination sheet\n",
        "        if validation_rules:\n",
        "            requests = [{'setDataValidation': {'range': rule['range'], 'rule': rule['rule']}} for rule in validation_rules]\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': requests}).execute()\n",
        "\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': source_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Assuming 26 columns (A to Z)\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        print(f\"Data, formulas, formatting, and data validation rules copied successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data and format copying: {e}\")\n",
        "\n",
        "copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hPf2An_SE2kk"
      },
      "outputs": [],
      "source": [
        "#@title Copying over from match template based on amount of matches\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def adjust_formula(formula, row_offset, current_row, reference_row, same_row_columns, section_size=5):\n",
        "    \"\"\"\n",
        "    Adjust the row references in a formula by a specific offset.\n",
        "    For specific rows and columns, the formulas will reference different rows based on the logic provided.\n",
        "    \"\"\"\n",
        "    cell_ref_regex = r'([A-Z\\$]+)(\\d+)'\n",
        "\n",
        "    def adjust_match(match):\n",
        "        col_ref = match.group(1)  # Column reference\n",
        "        row_ref = int(match.group(2))  # Row reference\n",
        "        if '$' not in col_ref:  # Skip absolute row references\n",
        "            if col_ref in same_row_columns and (current_row - reference_row) % section_size == 0:\n",
        "                # For specified columns in the first row of each section, reference the same row\n",
        "                adjusted_row_ref = current_row\n",
        "            elif col_ref in same_row_columns:\n",
        "                # For specified columns in other rows, reference the first row of the section\n",
        "                adjusted_row_ref = current_row - ((current_row - reference_row) % section_size)\n",
        "            else:\n",
        "                # For other columns, adjust normally\n",
        "                adjusted_row_ref = row_ref + row_offset\n",
        "            return f'{col_ref}{adjusted_row_ref}'\n",
        "        else:\n",
        "            return f'{col_ref}{row_ref}'\n",
        "\n",
        "    adjusted_formula = re.sub(cell_ref_regex, adjust_match, formula)\n",
        "    return adjusted_formula\n",
        "\n",
        "def replicate_formatting(sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the range to copy (rows 8-11)\n",
        "    copy_range = 'A8:AK11'\n",
        "\n",
        "    # Determine the number of rows to replicate based on 'Data 1' sheet\n",
        "    data_sheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "    data_rows = len(data_sheet.get_all_values())\n",
        "    rows_to_replicate = data_rows - 3\n",
        "\n",
        "    # Get the detailed data from the range to copy, including data validation rules\n",
        "    request = service.spreadsheets().get(spreadsheetId=sheet_id, ranges=[f'{dest_worksheet.title}!{copy_range}'], includeGridData=True)\n",
        "    source_data = request.execute()\n",
        "\n",
        "    # Extract data, formulas, formats, and data validation rules for updating the destination sheet\n",
        "    source_rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "    source_data_list = []\n",
        "    data_validation_rules = []\n",
        "    for row_index, row in enumerate(source_rows):\n",
        "        row_data = []\n",
        "        row_rules = []\n",
        "        for cell_index, cell in enumerate(row.get('values', [])):\n",
        "            # Data extraction\n",
        "            if 'userEnteredValue' in cell:\n",
        "                cell_value = cell['userEnteredValue']\n",
        "                if 'formulaValue' in cell_value:\n",
        "                    row_data.append(cell_value['formulaValue'])\n",
        "                elif 'stringValue' in cell_value:\n",
        "                    row_data.append(cell_value['stringValue'])\n",
        "                elif 'numberValue' in cell_value:\n",
        "                    row_data.append(cell_value['numberValue'])\n",
        "                elif 'boolValue' in cell_value:\n",
        "                    row_data.append(cell_value['boolValue'])\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            # Data validation rule extraction\n",
        "            if 'dataValidation' in cell:\n",
        "                rule = cell['dataValidation']\n",
        "                row_rules.append((row_index, cell_index, rule))\n",
        "        source_data_list.append(row_data)\n",
        "        data_validation_rules.extend(row_rules)\n",
        "\n",
        "    # Replicate the formatting, data, and data validation rules with gaps\n",
        "    original_row_count = 4  # Number of rows in the source range (8-11)\n",
        "    start_row = 12  # Start copying from row 13, leaving a gap after row 11\n",
        "    same_row_columns = {'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','AA','AB','AC','AE','AG','AH','AI','AJ', 'AK'}  # Columns that should always reference the same row\n",
        "\n",
        "    for i in range(rows_to_replicate):\n",
        "        row_offset = (original_row_count + 1) * i  # Calculate the offset for this replication\n",
        "        reference_row = start_row + 1  # The first row of the current section\n",
        "\n",
        "        # Data and formula adjustment\n",
        "        adjusted_data_list = []\n",
        "        for row_index, row in enumerate(source_data_list):\n",
        "            current_row = start_row + row_index + 1  # Calculate the current row\n",
        "            adjusted_row = []\n",
        "            for cell in row:\n",
        "                if isinstance(cell, str) and cell.startswith('='):  # Check if it's a formula\n",
        "                    adjusted_row.append(adjust_formula(cell, row_offset, current_row, reference_row, same_row_columns))\n",
        "                else:\n",
        "                    adjusted_row.append(cell)\n",
        "            adjusted_data_list.append(adjusted_row)\n",
        "\n",
        "        # Update values and formulas\n",
        "        dest_range = f'{dest_worksheet.title}!A{start_row + 1}:AK{start_row + 4}'\n",
        "        body = {'values': adjusted_data_list}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 7,\n",
        "                        'endRowIndex': 11,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Including column AK\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row,\n",
        "                        'endRowIndex': start_row + 4,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        # Apply data validation rules\n",
        "        for rule_index, (src_row, src_col, rule) in enumerate(data_validation_rules):\n",
        "            rule_request = {\n",
        "                'setDataValidation': {\n",
        "                    'range': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row + src_row,\n",
        "                        'endRowIndex': start_row + src_row + 1,\n",
        "                        'startColumnIndex': src_col,\n",
        "                        'endColumnIndex': src_col + 1,\n",
        "                    },\n",
        "                    'rule': rule\n",
        "                }\n",
        "            }\n",
        "            time.sleep(3.5)\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': [rule_request]}).execute()\n",
        "\n",
        "        # Update the starting row for the next replication\n",
        "        start_row += 5  # 4 rows of data plus 1 row gap\n",
        "\n",
        "    print(f\"Formats, data, and data validation rules replicated successfully for {rows_to_replicate} sections.\")\n",
        "\n",
        "# Call the function\n",
        "replicate_formatting(sheet_id, dest_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je-4veCkUQkp",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Copying over match data from data sheet\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def transfer_data(sheet_id, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        data_worksheet = dest_sheet.worksheet(source_worksheet_name)\n",
        "        day_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the columns to transfer and their destination columns\n",
        "    columns_to_transfer = {\n",
        "        4: 'AB',  # D2 onwards to AB3 onwards - time\n",
        "        1: 'AC',  # A2 onwards to AC3 onwards - player 1\n",
        "        2: 'AE',  # B2 onwards to AE3 onwards - player 2\n",
        "        3: 'Z',   # C2 onwards to Z3 onwards - round\n",
        "        6: 'AG'   # F2 onwards to AG3 onwards - court\n",
        "    }\n",
        "\n",
        "    for source_col, dest_col_prefix in columns_to_transfer.items():\n",
        "        # Get all values from the source column starting from row 2\n",
        "        values = data_worksheet.col_values(source_col)[1:]  # Skip the first row (title)\n",
        "\n",
        "        # Loop through the values\n",
        "        for i, value in enumerate(values, start=1):\n",
        "            # Calculate the destination row using the formula\n",
        "            dest_row = 3 + (i - 1) * 5\n",
        "\n",
        "            # Write the value to the calculated cell in 'Day 1'\n",
        "            time.sleep(2)\n",
        "            day_worksheet.update_acell(f'{dest_col_prefix}{dest_row}', value)\n",
        "        print(f\"Data from column {source_col} transferred to column {dest_col_prefix} for {len(values)} rows.\")\n",
        "\n",
        "# Call the function\n",
        "transfer_data(sheet_id, credentials_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Roland Garros Shells:**"
      ],
      "metadata": {
        "id": "SsbdofNAhHKM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dabaQ2hi3Sx"
      },
      "source": [
        "#### **FIRST:**\n",
        "Scraping from Roland Garros website TO HTML File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YQIkFFGUi3Sy"
      },
      "outputs": [],
      "source": [
        "#@title Enter the URL to Scrape\n",
        "url_to_scrape = \"https://www.rolandgarros.com/en-us/order-of-play?year=2023&competition=all&annexeCourt=all&principalCourt=all&favoriteFilter=false&country=all&date=2023-05-28\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n0L4hU2Fi3Sy"
      },
      "outputs": [],
      "source": [
        "#@title Writing scraping instructions in index.js file\n",
        "\n",
        "%%writefile roland.js\n",
        "'use strict';\n",
        "\n",
        "const puppeteer = require('puppeteer');\n",
        "const fs = require('fs');\n",
        "\n",
        "async function goPuppeteer(url) {\n",
        "  try {\n",
        "    const browser = await puppeteer.launch({\n",
        "      headless: \"new\",\n",
        "      args: ['--no-sandbox', '--disable-gpu']\n",
        "    });\n",
        "    const page = await browser.newPage();\n",
        "    await page.goto(url, {\n",
        "      waitUntil: 'load',\n",
        "      timeout: 0\n",
        "    });\n",
        "\n",
        "    const htmlContent = await page.content();\n",
        "    fs.writeFileSync('roland.html', htmlContent);\n",
        "    console.log(`Content saved from ${url}`);\n",
        "\n",
        "    await browser.close();\n",
        "  } catch (e) {\n",
        "    console.error(\"Error occurred:\", e);\n",
        "  }\n",
        "}\n",
        "\n",
        "// The first two elements of process.argv array are 'node' and the script name, so the third element (index 2) is the first argument.\n",
        "const url = process.argv[2];\n",
        "goPuppeteer(url);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezS0oBp1i3Sy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Running index.js file\n",
        "!node roland.js \"$url_to_scrape\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_qppE7uiHf5"
      },
      "source": [
        "#### **SECOND:**\n",
        "Taking data from HTML file and automating matches into shells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XyHWbk7jiHf5"
      },
      "outputs": [],
      "source": [
        "#@title Invoking Variables\n",
        "\n",
        "credentials_file ='/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'\n",
        "sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8'  #@param {type:\"string\"}\n",
        "template_sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8' #@param {type:\"string\"}\n",
        "template_worksheet_name = 'Roland Garros'\n",
        "sheet_range = 'A1:AK1000' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nMX-PiLxiHf5"
      },
      "outputs": [],
      "source": [
        "#@title Parsing data from HTML file to Google Sheets\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def extract_last_name(text):\n",
        "    \"\"\"\n",
        "    Extracts the player's last name, keeping numeric ranks and discarding non-numeric ranks.\n",
        "    \"\"\"\n",
        "    # Removing initials and splitting the text\n",
        "    cleaned_text = re.sub(r\"\\b[A-Z]\\.\\s*\", \"\", text)\n",
        "    parts = cleaned_text.split()\n",
        "\n",
        "    # Known non-numeric rank tags to exclude\n",
        "    known_non_numeric_ranks = {'Q', 'A', 'WC', 'LL'}\n",
        "\n",
        "    # Exclude known non-numeric rank tags and identify numeric rank if present\n",
        "    last_name_parts = []\n",
        "    rank = ''\n",
        "    for part in parts:\n",
        "        if part.isdigit():\n",
        "            rank = part\n",
        "        elif part not in known_non_numeric_ranks:\n",
        "            last_name_parts.append(part)\n",
        "\n",
        "    last_name = ' '.join(last_name_parts)\n",
        "\n",
        "    return last_name, rank\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "with open('roland.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract and format the date\n",
        "date_string = soup.select_one('.print-header__print-heading').get_text()\n",
        "extracted_date = re.search(r'\\d{1,2}\\s\\w+', date_string).group()\n",
        "date_input = datetime.strptime(extracted_date + ' 2024', '%d %B %Y').strftime('%Y-%m-%d')\n",
        "\n",
        "# Extracting the day (e.g., \"Day 1\")\n",
        "day_match = re.search(r'Day\\s\\d+', date_string)\n",
        "if day_match:\n",
        "    dest_worksheet_name = day_match.group()\n",
        "else:\n",
        "    dest_worksheet_name = 'Day Unknown'\n",
        "\n",
        "# Extracting the day number for source_worksheet_name\n",
        "day_number_match = re.search(r'Day\\s(\\d+)', date_string)\n",
        "if day_number_match:\n",
        "    day_number = day_number_match.group(1)\n",
        "    source_worksheet_name = 'Data'\n",
        "else:\n",
        "    source_worksheet_name = 'Data Unknown'\n",
        "\n",
        "# Initializing lists to store extracted data\n",
        "rounds, times, first_players, second_players, genders, courts, first_special, second_special, match_numbers = ([] for _ in range(9))\n",
        "\n",
        "match_number = 1\n",
        "\n",
        "# Extract data for each match\n",
        "for location in soup.select('.schedule-location'):\n",
        "    court_name = location.select_one('.schedule-location__location-title').get_text().strip()\n",
        "\n",
        "    for match in location.select('.score-row'):\n",
        "        # Extract round information\n",
        "        round_info = match.select_one('.score-header__subtitle')\n",
        "        rounds.append(round_info.get_text().split('•')[1].strip() if round_info else '')\n",
        "\n",
        "        # Extract time data\n",
        "        time_info = match.select_one('.schedule-location__session-text')\n",
        "        times.append(time_info.get_text().split('From')[1].strip() if time_info else '')\n",
        "\n",
        "        # Extract players and their ranks\n",
        "        player_groups = match.select('.player-row__team-wrapper')\n",
        "        if player_groups:\n",
        "            # Extract for first team\n",
        "            first_team_players = player_groups[0].select('p')\n",
        "            if len(first_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                first_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in first_team_players)\n",
        "                first_spec = ''\n",
        "            else:\n",
        "                first_names, first_spec = extract_last_name(first_team_players[0].get_text())\n",
        "\n",
        "            # Extract for second team\n",
        "            second_team_players = player_groups[1].select('p') if len(player_groups) > 1 else []\n",
        "            if len(second_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                second_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in second_team_players)\n",
        "                second_spec = ''\n",
        "            else:\n",
        "                second_names, second_spec = extract_last_name(second_team_players[0].get_text()) if second_team_players else ('', '')\n",
        "        else:\n",
        "            first_names, second_names, first_spec, second_spec = ('', '', '', '')\n",
        "\n",
        "        first_players.append(first_names)\n",
        "        second_players.append(second_names)\n",
        "        first_special.append(first_spec)\n",
        "        second_special.append(second_spec)\n",
        "\n",
        "        genders.append(round_info.get_text().split('•')[0].strip() if round_info else '')\n",
        "        courts.append(court_name)\n",
        "        match_numbers.append(match_number)\n",
        "        match_number += 1\n",
        "\n",
        "# Step 3: Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'First Player': first_players,\n",
        "    'Second Player': second_players,\n",
        "    'Round': rounds,\n",
        "    'Time': times,\n",
        "    'Gender': genders,\n",
        "    'Court': courts,\n",
        "    'Player 1 Rank': first_special,\n",
        "    'Player 2 Rank': second_special,\n",
        "    'Match Number': match_numbers\n",
        "})\n",
        "\n",
        "# Authenticate and connect to Google Sheets\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "\n",
        "# Check if the worksheet already exists, if not, create a new one\n",
        "try:\n",
        "    worksheet = sheet.worksheet(source_worksheet_name)\n",
        "except gspread.WorksheetNotFound:\n",
        "    worksheet = sheet.add_worksheet(title=source_worksheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame to a list of lists and upload to Google Sheets\n",
        "worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "worksheet.update('J1', match_number - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dzA8OQfIiHf6"
      },
      "outputs": [],
      "source": [
        "#@title Parsing the existing times\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pytz  # Ensure this is installed\n",
        "from bs4 import BeautifulSoup\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "worksheet = sheet.worksheet(source_worksheet_name)\n",
        "\n",
        "total_matches_script_a = int(worksheet.acell('J1').value)\n",
        "\n",
        "\n",
        "def convert_gmt_to_local_24hr(gmt_time_str):\n",
        "    \"\"\"Converts GMT time string to GMT+11 in 24-hour format and returns it.\"\"\"\n",
        "    try:\n",
        "        gmt_time = datetime.strptime(gmt_time_str, '%I:%M%p')\n",
        "        gmt_time = pytz.timezone('GMT').localize(gmt_time)\n",
        "        local_time = gmt_time.astimezone(pytz.timezone('Etc/GMT-11'))\n",
        "        return local_time.strftime('%H:%M')  # 24-hour format\n",
        "    except ValueError:\n",
        "        return ''\n",
        "\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "html_file_path = 'Scraped.html'  # Replace with your actual file path\n",
        "with open(html_file_path, 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# List to store extracted datetimes along with match numbers\n",
        "start_datetimes_with_numbers = []\n",
        "\n",
        "# Initialize match counter before the loop\n",
        "match_number = 1\n",
        "\n",
        "# Variable to store the current session time\n",
        "current_session_time = None\n",
        "time_assigned = False  # Flag to check if time is assigned to a session\n",
        "\n",
        "# Loop through each element in the HTML\n",
        "for element in soup.find_all(True, class_=['schedule-location__session-text', 'score-row']):\n",
        "    if 'schedule-location__session-text' in element.get('class', []):\n",
        "        # Extract the session time\n",
        "        time_text = element.get_text()\n",
        "        time_match = re.search(r'(From|Not before)\\s+(\\d+:\\d+\\w+)', time_text)\n",
        "        if time_match:\n",
        "            gmt_time = time_match.group(2)\n",
        "            local_time_24hr = convert_gmt_to_local_24hr(gmt_time)\n",
        "            current_session_time = datetime.strptime(f\"{date_input} {local_time_24hr}\", \"%Y-%m-%d %H:%M\") if local_time_24hr != '' else ''\n",
        "            time_assigned = True  # Time is assigned for this session\n",
        "        else:\n",
        "            current_session_time = ''\n",
        "            time_assigned = False  # No valid time for this session\n",
        "    elif 'score-row' in element.get('class', []):\n",
        "        # Assign the current session time to the match only if the time was assigned in the current session\n",
        "        if time_assigned:\n",
        "            start_datetimes_with_numbers.append((match_number, current_session_time))\n",
        "        else:\n",
        "            start_datetimes_with_numbers.append((match_number, ''))  # Or skip this line to not include matches without times\n",
        "\n",
        "        # Increment match counter\n",
        "        match_number += 1\n",
        "        time_assigned = False  # Reset the flag after assigning time to a match\n",
        "\n",
        "# Prepare data for writing (convert datetime objects to strings)\n",
        "data_to_write = []\n",
        "for match in start_datetimes_with_numbers:\n",
        "    # Convert datetime to string, or leave as 'N/A' if not a datetime object\n",
        "    datetime_str = match[1].strftime('%Y-%m-%d %H:%M') if isinstance(match[1], datetime) else match[1]\n",
        "    data_to_write.append([datetime_str])\n",
        "# Write data to Google Sheet starting from cell B2\n",
        "worksheet.update('D2', data_to_write)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lBJNGhcsiHf6"
      },
      "outputs": [],
      "source": [
        "#@title Calculating the rest of the times\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def update_missing_match_times(sheet_id, source_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "    worksheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "\n",
        "    # Read the data from the sheet\n",
        "    try:\n",
        "        data = worksheet.get_all_values()\n",
        "        matches = data[1:]  # Assuming the first row is a header\n",
        "\n",
        "        current_court = None\n",
        "        current_time = None\n",
        "        previous_match_type = None  # Track the type of the previous match\n",
        "\n",
        "        for i, row in enumerate(matches):\n",
        "            existing_time_str = row[3]  # Time information in Column D\n",
        "            court = row[5]  # Court information in Column F\n",
        "            match_type = row[4]  # Match type in Column E\n",
        "\n",
        "            if existing_time_str.strip():\n",
        "                # If there is an existing time, parse it and use it as the current time\n",
        "                current_time = datetime.strptime(existing_time_str, '%Y-%m-%d %H:%M')\n",
        "            else:\n",
        "                # Skip if current_time is not set (i.e., no previous match time to base on)\n",
        "                if not current_time:\n",
        "                    continue\n",
        "\n",
        "                # Calculate the match time based on the gender information\n",
        "                duration = timedelta(hours=3) if previous_match_type == \"Men's Singles\" else timedelta(hours=2)\n",
        "                current_time += duration\n",
        "\n",
        "                # Format the date-time in an ISO format recognized by Google Sheets\n",
        "                iso_formatted_time = current_time.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "                # Update the sheet with new value for this row\n",
        "                worksheet.update(f'D{i + 2}', [[iso_formatted_time]])  # i + 2 to write to the correct row\n",
        "\n",
        "            # Update court and previous match type for next iteration\n",
        "            current_court = court\n",
        "            previous_match_type = match_type\n",
        "\n",
        "        # Apply the desired date format to the column\n",
        "        date_format = {\"numberFormat\": {\"type\": \"DATE_TIME\", \"pattern\": \"dd/MM/yyyy HH:mm\"}}\n",
        "        worksheet.format('B2:B' + str(len(matches) + 1), date_format)\n",
        "\n",
        "        print(\"Missing match times updated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sheet: {e}\")\n",
        "\n",
        "# Example call to the function (replace with actual values)\n",
        "update_missing_match_times(sheet_id, source_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z3qp2g0fiHf6"
      },
      "outputs": [],
      "source": [
        "#@title Setting up initial Day from template\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the source and destination Google Sheets\n",
        "    try:\n",
        "        source_sheet = client.open_by_key(template_sheet_id)\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if the destination worksheet exists, create if not\n",
        "    try:\n",
        "        dest_worksheet = None\n",
        "        try:\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create a new worksheet\n",
        "            dest_sheet.add_worksheet(title=dest_worksheet_name, rows=\"1000\", cols=\"26\")  # Adjust rows and columns as needed\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "\n",
        "        source_worksheet = source_sheet.worksheet(template_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing or creating worksheets: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the detailed data from the source sheet\n",
        "        source_range = f'{source_worksheet.title}!{sheet_range}'\n",
        "        request = service.spreadsheets().get(spreadsheetId=template_sheet_id, ranges=[source_range], includeGridData=True)\n",
        "        source_data = request.execute()\n",
        "\n",
        "        # Extract data for updating the destination sheet\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            row_data = []\n",
        "            for cell in row.get('values', []):\n",
        "                # Handle different types of values including formulas\n",
        "                if 'userEnteredValue' in cell:\n",
        "                    cell_value = cell['userEnteredValue']\n",
        "                    if 'formulaValue' in cell_value:\n",
        "                        row_data.append(cell_value['formulaValue'])\n",
        "                    elif 'stringValue' in cell_value:\n",
        "                        row_data.append(cell_value['stringValue'])\n",
        "                    elif 'numberValue' in cell_value:\n",
        "                        row_data.append(cell_value['numberValue'])\n",
        "                    elif 'boolValue' in cell_value:\n",
        "                        row_data.append(cell_value['boolValue'])\n",
        "                    else:\n",
        "                        row_data.append('')\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Extract data validation rules\n",
        "        validation_rules = []\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        for i, row in enumerate(rows):\n",
        "            for j, cell in enumerate(row.get('values', [])):\n",
        "                if 'dataValidation' in cell:\n",
        "                    rule = cell['dataValidation']\n",
        "                    validation_rules.append({\n",
        "                        'range': {\n",
        "                            'sheetId': dest_worksheet.id,\n",
        "                            'startRowIndex': i,\n",
        "                            'endRowIndex': i + 1,\n",
        "                            'startColumnIndex': j,\n",
        "                            'endColumnIndex': j + 1\n",
        "                        },\n",
        "                        'rule': rule\n",
        "                    })\n",
        "\n",
        "        # Write values and formulas to the destination sheet\n",
        "        dest_range = f'{dest_worksheet.title}!{sheet_range}'\n",
        "        body = {'values': data}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Apply data validation rules to the destination sheet\n",
        "        if validation_rules:\n",
        "            requests = [{'setDataValidation': {'range': rule['range'], 'rule': rule['rule']}} for rule in validation_rules]\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': requests}).execute()\n",
        "\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': source_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Assuming 26 columns (A to Z)\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        print(f\"Data, formulas, formatting, and data validation rules copied successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data and format copying: {e}\")\n",
        "\n",
        "copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eBqtLNDOiHf6"
      },
      "outputs": [],
      "source": [
        "#@title Copying over from match template based on amount of matches\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def adjust_formula(formula, row_offset, current_row, reference_row, same_row_columns, section_size=5):\n",
        "    \"\"\"\n",
        "    Adjust the row references in a formula by a specific offset.\n",
        "    For specific rows and columns, the formulas will reference different rows based on the logic provided.\n",
        "    \"\"\"\n",
        "    cell_ref_regex = r'([A-Z\\$]+)(\\d+)'\n",
        "\n",
        "    def adjust_match(match):\n",
        "        col_ref = match.group(1)  # Column reference\n",
        "        row_ref = int(match.group(2))  # Row reference\n",
        "        if '$' not in col_ref:  # Skip absolute row references\n",
        "            if col_ref in same_row_columns and (current_row - reference_row) % section_size == 0:\n",
        "                # For specified columns in the first row of each section, reference the same row\n",
        "                adjusted_row_ref = current_row\n",
        "            elif col_ref in same_row_columns:\n",
        "                # For specified columns in other rows, reference the first row of the section\n",
        "                adjusted_row_ref = current_row - ((current_row - reference_row) % section_size)\n",
        "            else:\n",
        "                # For other columns, adjust normally\n",
        "                adjusted_row_ref = row_ref + row_offset\n",
        "            return f'{col_ref}{adjusted_row_ref}'\n",
        "        else:\n",
        "            return f'{col_ref}{row_ref}'\n",
        "\n",
        "    adjusted_formula = re.sub(cell_ref_regex, adjust_match, formula)\n",
        "    return adjusted_formula\n",
        "\n",
        "def replicate_formatting(sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the range to copy (rows 8-11)\n",
        "    copy_range = 'A8:AK11'\n",
        "\n",
        "    # Determine the number of rows to replicate based on 'Data 1' sheet\n",
        "    data_sheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "    data_rows = len(data_sheet.get_all_values())\n",
        "    rows_to_replicate = data_rows - 3\n",
        "\n",
        "    # Get the detailed data from the range to copy, including data validation rules\n",
        "    request = service.spreadsheets().get(spreadsheetId=sheet_id, ranges=[f'{dest_worksheet.title}!{copy_range}'], includeGridData=True)\n",
        "    source_data = request.execute()\n",
        "\n",
        "    # Extract data, formulas, formats, and data validation rules for updating the destination sheet\n",
        "    source_rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "    source_data_list = []\n",
        "    data_validation_rules = []\n",
        "    for row_index, row in enumerate(source_rows):\n",
        "        row_data = []\n",
        "        row_rules = []\n",
        "        for cell_index, cell in enumerate(row.get('values', [])):\n",
        "            # Data extraction\n",
        "            if 'userEnteredValue' in cell:\n",
        "                cell_value = cell['userEnteredValue']\n",
        "                if 'formulaValue' in cell_value:\n",
        "                    row_data.append(cell_value['formulaValue'])\n",
        "                elif 'stringValue' in cell_value:\n",
        "                    row_data.append(cell_value['stringValue'])\n",
        "                elif 'numberValue' in cell_value:\n",
        "                    row_data.append(cell_value['numberValue'])\n",
        "                elif 'boolValue' in cell_value:\n",
        "                    row_data.append(cell_value['boolValue'])\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            # Data validation rule extraction\n",
        "            if 'dataValidation' in cell:\n",
        "                rule = cell['dataValidation']\n",
        "                row_rules.append((row_index, cell_index, rule))\n",
        "        source_data_list.append(row_data)\n",
        "        data_validation_rules.extend(row_rules)\n",
        "\n",
        "    # Replicate the formatting, data, and data validation rules with gaps\n",
        "    original_row_count = 4  # Number of rows in the source range (8-11)\n",
        "    start_row = 12  # Start copying from row 13, leaving a gap after row 11\n",
        "    same_row_columns = {'B','C','E','F','H','K','L','W','X','Y','Z','AC','AE','AG','AA','aa'}  # Columns that should always reference the same row\n",
        "\n",
        "    for i in range(rows_to_replicate):\n",
        "        row_offset = (original_row_count + 1) * i  # Calculate the offset for this replication\n",
        "        reference_row = start_row + 1  # The first row of the current section\n",
        "\n",
        "        # Data and formula adjustment\n",
        "        adjusted_data_list = []\n",
        "        for row_index, row in enumerate(source_data_list):\n",
        "            current_row = start_row + row_index + 1  # Calculate the current row\n",
        "            adjusted_row = []\n",
        "            for cell in row:\n",
        "                if isinstance(cell, str) and cell.startswith('='):  # Check if it's a formula\n",
        "                    adjusted_row.append(adjust_formula(cell, row_offset, current_row, reference_row, same_row_columns))\n",
        "                else:\n",
        "                    adjusted_row.append(cell)\n",
        "            adjusted_data_list.append(adjusted_row)\n",
        "\n",
        "        # Update values and formulas\n",
        "        dest_range = f'{dest_worksheet.title}!A{start_row + 1}:AK{start_row + 4}'\n",
        "        body = {'values': adjusted_data_list}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 7,\n",
        "                        'endRowIndex': 11,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Including column AK\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row,\n",
        "                        'endRowIndex': start_row + 4,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        # Apply data validation rules\n",
        "        for rule_index, (src_row, src_col, rule) in enumerate(data_validation_rules):\n",
        "            rule_request = {\n",
        "                'setDataValidation': {\n",
        "                    'range': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row + src_row,\n",
        "                        'endRowIndex': start_row + src_row + 1,\n",
        "                        'startColumnIndex': src_col,\n",
        "                        'endColumnIndex': src_col + 1,\n",
        "                    },\n",
        "                    'rule': rule\n",
        "                }\n",
        "            }\n",
        "            time.sleep(3.5)\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': [rule_request]}).execute()\n",
        "\n",
        "        # Update the starting row for the next replication\n",
        "        start_row += 5  # 4 rows of data plus 1 row gap\n",
        "\n",
        "    print(f\"Formats, data, and data validation rules replicated successfully for {rows_to_replicate} sections.\")\n",
        "\n",
        "# Call the function\n",
        "replicate_formatting(sheet_id, dest_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7FbuI7XLiHf6"
      },
      "outputs": [],
      "source": [
        "#@title Copying over match data from data sheet\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def transfer_data(sheet_id, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        data_worksheet = dest_sheet.worksheet(source_worksheet_name)\n",
        "        day_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the columns to transfer and their destination columns\n",
        "    columns_to_transfer = {\n",
        "        4: 'AB',  # D2 onwards to AB3 onwards - time\n",
        "        1: 'AC',  # A2 onwards to AC3 onwards - player 1\n",
        "        2: 'AE',  # B2 onwards to AE3 onwards - player 2\n",
        "        3: 'Z',   # C2 onwards to Z3 onwards - round\n",
        "        6: 'AG'   # F2 onwards to AG3 onwards - court\n",
        "    }\n",
        "\n",
        "    for source_col, dest_col_prefix in columns_to_transfer.items():\n",
        "        # Get all values from the source column starting from row 2\n",
        "        values = data_worksheet.col_values(source_col)[1:]  # Skip the first row (title)\n",
        "\n",
        "        # Loop through the values\n",
        "        for i, value in enumerate(values, start=1):\n",
        "            # Calculate the destination row using the formula\n",
        "            dest_row = 3 + (i - 1) * 5\n",
        "\n",
        "            # Write the value to the calculated cell in 'Day 1'\n",
        "            time.sleep(2)\n",
        "            day_worksheet.update_acell(f'{dest_col_prefix}{dest_row}', value)\n",
        "        print(f\"Data from column {source_col} transferred to column {dest_col_prefix} for {len(values)} rows.\")\n",
        "\n",
        "# Call the function\n",
        "transfer_data(sheet_id, credentials_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSYxxHiXjMZ7"
      },
      "source": [
        "### **Wimbledon Shells:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-i2Vzm5jMaB"
      },
      "source": [
        "#### **FIRST:**\n",
        "Scraping from Wimbledon website TO HTML File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-3uPMepajMaB"
      },
      "outputs": [],
      "source": [
        "#@title Enter the URL to Scrape\n",
        "url_to_scrape = \"https://ausopen.com/schedule#!40008\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TaTiX4ECjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Writing scraping instructions in index.js file\n",
        "\n",
        "%%writefile index.js\n",
        "'use strict';\n",
        "\n",
        "const puppeteer = require('puppeteer');\n",
        "const fs = require('fs');\n",
        "\n",
        "async function goPuppeteer(url) {\n",
        "  try {\n",
        "    const browser = await puppeteer.launch({\n",
        "      headless: \"new\",\n",
        "      args: ['--no-sandbox', '--disable-gpu']\n",
        "    });\n",
        "    const page = await browser.newPage();\n",
        "    await page.goto(url, {\n",
        "      waitUntil: 'load',\n",
        "      timeout: 0\n",
        "    });\n",
        "\n",
        "    const htmlContent = await page.content();\n",
        "    fs.writeFileSync('Scraped.html', htmlContent);\n",
        "    console.log(`Content saved from ${url}`);\n",
        "\n",
        "    await browser.close();\n",
        "  } catch (e) {\n",
        "    console.error(\"Error occurred:\", e);\n",
        "  }\n",
        "}\n",
        "\n",
        "// The first two elements of process.argv array are 'node' and the script name, so the third element (index 2) is the first argument.\n",
        "const url = process.argv[2];\n",
        "goPuppeteer(url);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcR-5O1wjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Running index.js file\n",
        "!node index.js \"$url_to_scrape\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRbJjLatjMaB"
      },
      "source": [
        "#### **SECOND:**\n",
        "Taking data from HTML file and automating matches into shells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZJkYmNOjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Invoking Variables\n",
        "\n",
        "credentials_file ='/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'\n",
        "sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8'  #@param {type:\"string\"}\n",
        "template_sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8' #@param {type:\"string\"}\n",
        "template_worksheet_name = 'Wimbledon'\n",
        "sheet_range = 'A1:AK1000' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6W3vsmVbjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Parsing data from HTML file to Google Sheets\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def extract_last_name(text):\n",
        "    \"\"\"\n",
        "    Extracts the player's last name, keeping numeric ranks and discarding non-numeric ranks.\n",
        "    \"\"\"\n",
        "    # Removing initials and splitting the text\n",
        "    cleaned_text = re.sub(r\"\\b[A-Z]\\.\\s*\", \"\", text)\n",
        "    parts = cleaned_text.split()\n",
        "\n",
        "    # Known non-numeric rank tags to exclude\n",
        "    known_non_numeric_ranks = {'Q', 'A', 'WC', 'LL'}\n",
        "\n",
        "    # Exclude known non-numeric rank tags and identify numeric rank if present\n",
        "    last_name_parts = []\n",
        "    rank = ''\n",
        "    for part in parts:\n",
        "        if part.isdigit():\n",
        "            rank = part\n",
        "        elif part not in known_non_numeric_ranks:\n",
        "            last_name_parts.append(part)\n",
        "\n",
        "    last_name = ' '.join(last_name_parts)\n",
        "\n",
        "    return last_name, rank\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "with open('Scraped.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract and format the date\n",
        "date_string = soup.select_one('.print-header__print-heading').get_text()\n",
        "extracted_date = re.search(r'\\d{1,2}\\s\\w+', date_string).group()\n",
        "date_input = datetime.strptime(extracted_date + ' 2024', '%d %B %Y').strftime('%Y-%m-%d')\n",
        "\n",
        "# Extracting the day (e.g., \"Day 1\")\n",
        "day_match = re.search(r'Day\\s\\d+', date_string)\n",
        "if day_match:\n",
        "    dest_worksheet_name = day_match.group()\n",
        "else:\n",
        "    dest_worksheet_name = 'Day Unknown'\n",
        "\n",
        "# Extracting the day number for source_worksheet_name\n",
        "day_number_match = re.search(r'Day\\s(\\d+)', date_string)\n",
        "if day_number_match:\n",
        "    day_number = day_number_match.group(1)\n",
        "    source_worksheet_name = 'Data'\n",
        "else:\n",
        "    source_worksheet_name = 'Data Unknown'\n",
        "\n",
        "# Initializing lists to store extracted data\n",
        "rounds, times, first_players, second_players, genders, courts, first_special, second_special, match_numbers = ([] for _ in range(9))\n",
        "\n",
        "match_number = 1\n",
        "\n",
        "# Extract data for each match\n",
        "for location in soup.select('.schedule-location'):\n",
        "    court_name = location.select_one('.schedule-location__location-title').get_text().strip()\n",
        "\n",
        "    for match in location.select('.score-row'):\n",
        "        # Extract round information\n",
        "        round_info = match.select_one('.score-header__subtitle')\n",
        "        rounds.append(round_info.get_text().split('•')[1].strip() if round_info else '')\n",
        "\n",
        "        # Extract time data\n",
        "        time_info = match.select_one('.schedule-location__session-text')\n",
        "        times.append(time_info.get_text().split('From')[1].strip() if time_info else '')\n",
        "\n",
        "        # Extract players and their ranks\n",
        "        player_groups = match.select('.player-row__team-wrapper')\n",
        "        if player_groups:\n",
        "            # Extract for first team\n",
        "            first_team_players = player_groups[0].select('p')\n",
        "            if len(first_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                first_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in first_team_players)\n",
        "                first_spec = ''\n",
        "            else:\n",
        "                first_names, first_spec = extract_last_name(first_team_players[0].get_text())\n",
        "\n",
        "            # Extract for second team\n",
        "            second_team_players = player_groups[1].select('p') if len(player_groups) > 1 else []\n",
        "            if len(second_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                second_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in second_team_players)\n",
        "                second_spec = ''\n",
        "            else:\n",
        "                second_names, second_spec = extract_last_name(second_team_players[0].get_text()) if second_team_players else ('', '')\n",
        "        else:\n",
        "            first_names, second_names, first_spec, second_spec = ('', '', '', '')\n",
        "\n",
        "        first_players.append(first_names)\n",
        "        second_players.append(second_names)\n",
        "        first_special.append(first_spec)\n",
        "        second_special.append(second_spec)\n",
        "\n",
        "        genders.append(round_info.get_text().split('•')[0].strip() if round_info else '')\n",
        "        courts.append(court_name)\n",
        "        match_numbers.append(match_number)\n",
        "        match_number += 1\n",
        "\n",
        "# Step 3: Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'First Player': first_players,\n",
        "    'Second Player': second_players,\n",
        "    'Round': rounds,\n",
        "    'Time': times,\n",
        "    'Gender': genders,\n",
        "    'Court': courts,\n",
        "    'Player 1 Rank': first_special,\n",
        "    'Player 2 Rank': second_special,\n",
        "    'Match Number': match_numbers\n",
        "})\n",
        "\n",
        "# Authenticate and connect to Google Sheets\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "\n",
        "# Check if the worksheet already exists, if not, create a new one\n",
        "try:\n",
        "    worksheet = sheet.worksheet(source_worksheet_name)\n",
        "except gspread.WorksheetNotFound:\n",
        "    worksheet = sheet.add_worksheet(title=source_worksheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame to a list of lists and upload to Google Sheets\n",
        "worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "worksheet.update('J1', match_number - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "n9kYTRdcjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Parsing the existing times\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pytz  # Ensure this is installed\n",
        "from bs4 import BeautifulSoup\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "worksheet = sheet.worksheet(source_worksheet_name)\n",
        "\n",
        "total_matches_script_a = int(worksheet.acell('J1').value)\n",
        "\n",
        "\n",
        "def convert_gmt_to_local_24hr(gmt_time_str):\n",
        "    \"\"\"Converts GMT time string to GMT+11 in 24-hour format and returns it.\"\"\"\n",
        "    try:\n",
        "        gmt_time = datetime.strptime(gmt_time_str, '%I:%M%p')\n",
        "        gmt_time = pytz.timezone('GMT').localize(gmt_time)\n",
        "        local_time = gmt_time.astimezone(pytz.timezone('Etc/GMT-11'))\n",
        "        return local_time.strftime('%H:%M')  # 24-hour format\n",
        "    except ValueError:\n",
        "        return ''\n",
        "\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "html_file_path = 'Scraped.html'  # Replace with your actual file path\n",
        "with open(html_file_path, 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# List to store extracted datetimes along with match numbers\n",
        "start_datetimes_with_numbers = []\n",
        "\n",
        "# Initialize match counter before the loop\n",
        "match_number = 1\n",
        "\n",
        "# Variable to store the current session time\n",
        "current_session_time = None\n",
        "time_assigned = False  # Flag to check if time is assigned to a session\n",
        "\n",
        "# Loop through each element in the HTML\n",
        "for element in soup.find_all(True, class_=['schedule-location__session-text', 'score-row']):\n",
        "    if 'schedule-location__session-text' in element.get('class', []):\n",
        "        # Extract the session time\n",
        "        time_text = element.get_text()\n",
        "        time_match = re.search(r'(From|Not before)\\s+(\\d+:\\d+\\w+)', time_text)\n",
        "        if time_match:\n",
        "            gmt_time = time_match.group(2)\n",
        "            local_time_24hr = convert_gmt_to_local_24hr(gmt_time)\n",
        "            current_session_time = datetime.strptime(f\"{date_input} {local_time_24hr}\", \"%Y-%m-%d %H:%M\") if local_time_24hr != '' else ''\n",
        "            time_assigned = True  # Time is assigned for this session\n",
        "        else:\n",
        "            current_session_time = ''\n",
        "            time_assigned = False  # No valid time for this session\n",
        "    elif 'score-row' in element.get('class', []):\n",
        "        # Assign the current session time to the match only if the time was assigned in the current session\n",
        "        if time_assigned:\n",
        "            start_datetimes_with_numbers.append((match_number, current_session_time))\n",
        "        else:\n",
        "            start_datetimes_with_numbers.append((match_number, ''))  # Or skip this line to not include matches without times\n",
        "\n",
        "        # Increment match counter\n",
        "        match_number += 1\n",
        "        time_assigned = False  # Reset the flag after assigning time to a match\n",
        "\n",
        "# Prepare data for writing (convert datetime objects to strings)\n",
        "data_to_write = []\n",
        "for match in start_datetimes_with_numbers:\n",
        "    # Convert datetime to string, or leave as 'N/A' if not a datetime object\n",
        "    datetime_str = match[1].strftime('%Y-%m-%d %H:%M') if isinstance(match[1], datetime) else match[1]\n",
        "    data_to_write.append([datetime_str])\n",
        "# Write data to Google Sheet starting from cell B2\n",
        "worksheet.update('D2', data_to_write)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qWR9AUvfjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Calculating the rest of the times\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def update_missing_match_times(sheet_id, source_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "    worksheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "\n",
        "    # Read the data from the sheet\n",
        "    try:\n",
        "        data = worksheet.get_all_values()\n",
        "        matches = data[1:]  # Assuming the first row is a header\n",
        "\n",
        "        current_court = None\n",
        "        current_time = None\n",
        "        previous_match_type = None  # Track the type of the previous match\n",
        "\n",
        "        for i, row in enumerate(matches):\n",
        "            existing_time_str = row[3]  # Time information in Column D\n",
        "            court = row[5]  # Court information in Column F\n",
        "            match_type = row[4]  # Match type in Column E\n",
        "\n",
        "            if existing_time_str.strip():\n",
        "                # If there is an existing time, parse it and use it as the current time\n",
        "                current_time = datetime.strptime(existing_time_str, '%Y-%m-%d %H:%M')\n",
        "            else:\n",
        "                # Skip if current_time is not set (i.e., no previous match time to base on)\n",
        "                if not current_time:\n",
        "                    continue\n",
        "\n",
        "                # Calculate the match time based on the gender information\n",
        "                duration = timedelta(hours=3) if previous_match_type == \"Men's Singles\" else timedelta(hours=2)\n",
        "                current_time += duration\n",
        "\n",
        "                # Format the date-time in an ISO format recognized by Google Sheets\n",
        "                iso_formatted_time = current_time.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "                # Update the sheet with new value for this row\n",
        "                worksheet.update(f'D{i + 2}', [[iso_formatted_time]])  # i + 2 to write to the correct row\n",
        "\n",
        "            # Update court and previous match type for next iteration\n",
        "            current_court = court\n",
        "            previous_match_type = match_type\n",
        "\n",
        "        # Apply the desired date format to the column\n",
        "        date_format = {\"numberFormat\": {\"type\": \"DATE_TIME\", \"pattern\": \"dd/MM/yyyy HH:mm\"}}\n",
        "        worksheet.format('B2:B' + str(len(matches) + 1), date_format)\n",
        "\n",
        "        print(\"Missing match times updated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sheet: {e}\")\n",
        "\n",
        "# Example call to the function (replace with actual values)\n",
        "update_missing_match_times(sheet_id, source_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RBoVxspNjMaB"
      },
      "outputs": [],
      "source": [
        "#@title Setting up initial Day from template\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the source and destination Google Sheets\n",
        "    try:\n",
        "        source_sheet = client.open_by_key(template_sheet_id)\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if the destination worksheet exists, create if not\n",
        "    try:\n",
        "        dest_worksheet = None\n",
        "        try:\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create a new worksheet\n",
        "            dest_sheet.add_worksheet(title=dest_worksheet_name, rows=\"1000\", cols=\"26\")  # Adjust rows and columns as needed\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "\n",
        "        source_worksheet = source_sheet.worksheet(template_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing or creating worksheets: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the detailed data from the source sheet\n",
        "        source_range = f'{source_worksheet.title}!{sheet_range}'\n",
        "        request = service.spreadsheets().get(spreadsheetId=template_sheet_id, ranges=[source_range], includeGridData=True)\n",
        "        source_data = request.execute()\n",
        "\n",
        "        # Extract data for updating the destination sheet\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            row_data = []\n",
        "            for cell in row.get('values', []):\n",
        "                # Handle different types of values including formulas\n",
        "                if 'userEnteredValue' in cell:\n",
        "                    cell_value = cell['userEnteredValue']\n",
        "                    if 'formulaValue' in cell_value:\n",
        "                        row_data.append(cell_value['formulaValue'])\n",
        "                    elif 'stringValue' in cell_value:\n",
        "                        row_data.append(cell_value['stringValue'])\n",
        "                    elif 'numberValue' in cell_value:\n",
        "                        row_data.append(cell_value['numberValue'])\n",
        "                    elif 'boolValue' in cell_value:\n",
        "                        row_data.append(cell_value['boolValue'])\n",
        "                    else:\n",
        "                        row_data.append('')\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Extract data validation rules\n",
        "        validation_rules = []\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        for i, row in enumerate(rows):\n",
        "            for j, cell in enumerate(row.get('values', [])):\n",
        "                if 'dataValidation' in cell:\n",
        "                    rule = cell['dataValidation']\n",
        "                    validation_rules.append({\n",
        "                        'range': {\n",
        "                            'sheetId': dest_worksheet.id,\n",
        "                            'startRowIndex': i,\n",
        "                            'endRowIndex': i + 1,\n",
        "                            'startColumnIndex': j,\n",
        "                            'endColumnIndex': j + 1\n",
        "                        },\n",
        "                        'rule': rule\n",
        "                    })\n",
        "\n",
        "        # Write values and formulas to the destination sheet\n",
        "        dest_range = f'{dest_worksheet.title}!{sheet_range}'\n",
        "        body = {'values': data}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Apply data validation rules to the destination sheet\n",
        "        if validation_rules:\n",
        "            requests = [{'setDataValidation': {'range': rule['range'], 'rule': rule['rule']}} for rule in validation_rules]\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': requests}).execute()\n",
        "\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': source_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Assuming 26 columns (A to Z)\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        print(f\"Data, formulas, formatting, and data validation rules copied successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data and format copying: {e}\")\n",
        "\n",
        "copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hMxg2CoGjMaC"
      },
      "outputs": [],
      "source": [
        "#@title Copying over from match template based on amount of matches\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def adjust_formula(formula, row_offset, current_row, reference_row, same_row_columns, section_size=5):\n",
        "    \"\"\"\n",
        "    Adjust the row references in a formula by a specific offset.\n",
        "    For specific rows and columns, the formulas will reference different rows based on the logic provided.\n",
        "    \"\"\"\n",
        "    cell_ref_regex = r'([A-Z\\$]+)(\\d+)'\n",
        "\n",
        "    def adjust_match(match):\n",
        "        col_ref = match.group(1)  # Column reference\n",
        "        row_ref = int(match.group(2))  # Row reference\n",
        "        if '$' not in col_ref:  # Skip absolute row references\n",
        "            if col_ref in same_row_columns and (current_row - reference_row) % section_size == 0:\n",
        "                # For specified columns in the first row of each section, reference the same row\n",
        "                adjusted_row_ref = current_row\n",
        "            elif col_ref in same_row_columns:\n",
        "                # For specified columns in other rows, reference the first row of the section\n",
        "                adjusted_row_ref = current_row - ((current_row - reference_row) % section_size)\n",
        "            else:\n",
        "                # For other columns, adjust normally\n",
        "                adjusted_row_ref = row_ref + row_offset\n",
        "            return f'{col_ref}{adjusted_row_ref}'\n",
        "        else:\n",
        "            return f'{col_ref}{row_ref}'\n",
        "\n",
        "    adjusted_formula = re.sub(cell_ref_regex, adjust_match, formula)\n",
        "    return adjusted_formula\n",
        "\n",
        "def replicate_formatting(sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the range to copy (rows 8-11)\n",
        "    copy_range = 'A8:AK11'\n",
        "\n",
        "    # Determine the number of rows to replicate based on 'Data 1' sheet\n",
        "    data_sheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "    data_rows = len(data_sheet.get_all_values())\n",
        "    rows_to_replicate = data_rows - 3\n",
        "\n",
        "    # Get the detailed data from the range to copy, including data validation rules\n",
        "    request = service.spreadsheets().get(spreadsheetId=sheet_id, ranges=[f'{dest_worksheet.title}!{copy_range}'], includeGridData=True)\n",
        "    source_data = request.execute()\n",
        "\n",
        "    # Extract data, formulas, formats, and data validation rules for updating the destination sheet\n",
        "    source_rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "    source_data_list = []\n",
        "    data_validation_rules = []\n",
        "    for row_index, row in enumerate(source_rows):\n",
        "        row_data = []\n",
        "        row_rules = []\n",
        "        for cell_index, cell in enumerate(row.get('values', [])):\n",
        "            # Data extraction\n",
        "            if 'userEnteredValue' in cell:\n",
        "                cell_value = cell['userEnteredValue']\n",
        "                if 'formulaValue' in cell_value:\n",
        "                    row_data.append(cell_value['formulaValue'])\n",
        "                elif 'stringValue' in cell_value:\n",
        "                    row_data.append(cell_value['stringValue'])\n",
        "                elif 'numberValue' in cell_value:\n",
        "                    row_data.append(cell_value['numberValue'])\n",
        "                elif 'boolValue' in cell_value:\n",
        "                    row_data.append(cell_value['boolValue'])\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            # Data validation rule extraction\n",
        "            if 'dataValidation' in cell:\n",
        "                rule = cell['dataValidation']\n",
        "                row_rules.append((row_index, cell_index, rule))\n",
        "        source_data_list.append(row_data)\n",
        "        data_validation_rules.extend(row_rules)\n",
        "\n",
        "    # Replicate the formatting, data, and data validation rules with gaps\n",
        "    original_row_count = 4  # Number of rows in the source range (8-11)\n",
        "    start_row = 12  # Start copying from row 13, leaving a gap after row 11\n",
        "    same_row_columns = {'B','C','E','F','H','K','L','W','X','Y','Z','AC','AE','AG','AA','aa'}  # Columns that should always reference the same row\n",
        "\n",
        "    for i in range(rows_to_replicate):\n",
        "        row_offset = (original_row_count + 1) * i  # Calculate the offset for this replication\n",
        "        reference_row = start_row + 1  # The first row of the current section\n",
        "\n",
        "        # Data and formula adjustment\n",
        "        adjusted_data_list = []\n",
        "        for row_index, row in enumerate(source_data_list):\n",
        "            current_row = start_row + row_index + 1  # Calculate the current row\n",
        "            adjusted_row = []\n",
        "            for cell in row:\n",
        "                if isinstance(cell, str) and cell.startswith('='):  # Check if it's a formula\n",
        "                    adjusted_row.append(adjust_formula(cell, row_offset, current_row, reference_row, same_row_columns))\n",
        "                else:\n",
        "                    adjusted_row.append(cell)\n",
        "            adjusted_data_list.append(adjusted_row)\n",
        "\n",
        "        # Update values and formulas\n",
        "        dest_range = f'{dest_worksheet.title}!A{start_row + 1}:AK{start_row + 4}'\n",
        "        body = {'values': adjusted_data_list}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 7,\n",
        "                        'endRowIndex': 11,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Including column AK\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row,\n",
        "                        'endRowIndex': start_row + 4,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        # Apply data validation rules\n",
        "        for rule_index, (src_row, src_col, rule) in enumerate(data_validation_rules):\n",
        "            rule_request = {\n",
        "                'setDataValidation': {\n",
        "                    'range': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row + src_row,\n",
        "                        'endRowIndex': start_row + src_row + 1,\n",
        "                        'startColumnIndex': src_col,\n",
        "                        'endColumnIndex': src_col + 1,\n",
        "                    },\n",
        "                    'rule': rule\n",
        "                }\n",
        "            }\n",
        "            time.sleep(3.5)\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': [rule_request]}).execute()\n",
        "\n",
        "        # Update the starting row for the next replication\n",
        "        start_row += 5  # 4 rows of data plus 1 row gap\n",
        "\n",
        "    print(f\"Formats, data, and data validation rules replicated successfully for {rows_to_replicate} sections.\")\n",
        "\n",
        "# Call the function\n",
        "replicate_formatting(sheet_id, dest_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vZam7NuRjMaC"
      },
      "outputs": [],
      "source": [
        "#@title Copying over match data from data sheet\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def transfer_data(sheet_id, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        data_worksheet = dest_sheet.worksheet(source_worksheet_name)\n",
        "        day_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the columns to transfer and their destination columns\n",
        "    columns_to_transfer = {\n",
        "        4: 'AB',  # D2 onwards to AB3 onwards - time\n",
        "        1: 'AC',  # A2 onwards to AC3 onwards - player 1\n",
        "        2: 'AE',  # B2 onwards to AE3 onwards - player 2\n",
        "        3: 'Z',   # C2 onwards to Z3 onwards - round\n",
        "        6: 'AG'   # F2 onwards to AG3 onwards - court\n",
        "    }\n",
        "\n",
        "    for source_col, dest_col_prefix in columns_to_transfer.items():\n",
        "        # Get all values from the source column starting from row 2\n",
        "        values = data_worksheet.col_values(source_col)[1:]  # Skip the first row (title)\n",
        "\n",
        "        # Loop through the values\n",
        "        for i, value in enumerate(values, start=1):\n",
        "            # Calculate the destination row using the formula\n",
        "            dest_row = 3 + (i - 1) * 5\n",
        "\n",
        "            # Write the value to the calculated cell in 'Day 1'\n",
        "            time.sleep(2)\n",
        "            day_worksheet.update_acell(f'{dest_col_prefix}{dest_row}', value)\n",
        "        print(f\"Data from column {source_col} transferred to column {dest_col_prefix} for {len(values)} rows.\")\n",
        "\n",
        "# Call the function\n",
        "transfer_data(sheet_id, credentials_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD4nwbMkkV7_"
      },
      "source": [
        "### **US Open Shells:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4F_uAjkkV8F"
      },
      "source": [
        "#### **FIRST:**\n",
        "Scraping from US Open website TO HTML File."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XF0IF_FRkV8F"
      },
      "outputs": [],
      "source": [
        "#@title Enter the URL to Scrape\n",
        "url_to_scrape = \"https://ausopen.com/schedule#!40008\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oikKVD-VkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Writing scraping instructions in index.js file\n",
        "\n",
        "%%writefile index.js\n",
        "'use strict';\n",
        "\n",
        "const puppeteer = require('puppeteer');\n",
        "const fs = require('fs');\n",
        "\n",
        "async function goPuppeteer(url) {\n",
        "  try {\n",
        "    const browser = await puppeteer.launch({\n",
        "      headless: \"new\",\n",
        "      args: ['--no-sandbox', '--disable-gpu']\n",
        "    });\n",
        "    const page = await browser.newPage();\n",
        "    await page.goto(url, {\n",
        "      waitUntil: 'load',\n",
        "      timeout: 0\n",
        "    });\n",
        "\n",
        "    const htmlContent = await page.content();\n",
        "    fs.writeFileSync('Scraped.html', htmlContent);\n",
        "    console.log(`Content saved from ${url}`);\n",
        "\n",
        "    await browser.close();\n",
        "  } catch (e) {\n",
        "    console.error(\"Error occurred:\", e);\n",
        "  }\n",
        "}\n",
        "\n",
        "// The first two elements of process.argv array are 'node' and the script name, so the third element (index 2) is the first argument.\n",
        "const url = process.argv[2];\n",
        "goPuppeteer(url);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkiTklPhkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Running index.js file\n",
        "!node index.js \"$url_to_scrape\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdiJRlkZkV8G"
      },
      "source": [
        "#### **SECOND:**\n",
        "Taking data from HTML file and automating matches into shells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9Ql5BAGkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Invoking Variables\n",
        "\n",
        "credentials_file ='/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'\n",
        "sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8'  #@param {type:\"string\"}\n",
        "template_sheet_id = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8' #@param {type:\"string\"}\n",
        "template_worksheet_name = 'US Open'\n",
        "sheet_range = 'A1:AK1000' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Kx5s-QjLkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Parsing data from HTML file to Google Sheets\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import re\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "def extract_last_name(text):\n",
        "    \"\"\"\n",
        "    Extracts the player's last name, keeping numeric ranks and discarding non-numeric ranks.\n",
        "    \"\"\"\n",
        "    # Removing initials and splitting the text\n",
        "    cleaned_text = re.sub(r\"\\b[A-Z]\\.\\s*\", \"\", text)\n",
        "    parts = cleaned_text.split()\n",
        "\n",
        "    # Known non-numeric rank tags to exclude\n",
        "    known_non_numeric_ranks = {'Q', 'A', 'WC', 'LL'}\n",
        "\n",
        "    # Exclude known non-numeric rank tags and identify numeric rank if present\n",
        "    last_name_parts = []\n",
        "    rank = ''\n",
        "    for part in parts:\n",
        "        if part.isdigit():\n",
        "            rank = part\n",
        "        elif part not in known_non_numeric_ranks:\n",
        "            last_name_parts.append(part)\n",
        "\n",
        "    last_name = ' '.join(last_name_parts)\n",
        "\n",
        "    return last_name, rank\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "with open('Scraped.html', 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract and format the date\n",
        "date_string = soup.select_one('.print-header__print-heading').get_text()\n",
        "extracted_date = re.search(r'\\d{1,2}\\s\\w+', date_string).group()\n",
        "date_input = datetime.strptime(extracted_date + ' 2024', '%d %B %Y').strftime('%Y-%m-%d')\n",
        "\n",
        "# Extracting the day (e.g., \"Day 1\")\n",
        "day_match = re.search(r'Day\\s\\d+', date_string)\n",
        "if day_match:\n",
        "    dest_worksheet_name = day_match.group()\n",
        "else:\n",
        "    dest_worksheet_name = 'Day Unknown'\n",
        "\n",
        "# Extracting the day number for source_worksheet_name\n",
        "day_number_match = re.search(r'Day\\s(\\d+)', date_string)\n",
        "if day_number_match:\n",
        "    day_number = day_number_match.group(1)\n",
        "    source_worksheet_name = 'Data'\n",
        "else:\n",
        "    source_worksheet_name = 'Data Unknown'\n",
        "\n",
        "# Initializing lists to store extracted data\n",
        "rounds, times, first_players, second_players, genders, courts, first_special, second_special, match_numbers = ([] for _ in range(9))\n",
        "\n",
        "match_number = 1\n",
        "\n",
        "# Extract data for each match\n",
        "for location in soup.select('.schedule-location'):\n",
        "    court_name = location.select_one('.schedule-location__location-title').get_text().strip()\n",
        "\n",
        "    for match in location.select('.score-row'):\n",
        "        # Extract round information\n",
        "        round_info = match.select_one('.score-header__subtitle')\n",
        "        rounds.append(round_info.get_text().split('•')[1].strip() if round_info else '')\n",
        "\n",
        "        # Extract time data\n",
        "        time_info = match.select_one('.schedule-location__session-text')\n",
        "        times.append(time_info.get_text().split('From')[1].strip() if time_info else '')\n",
        "\n",
        "        # Extract players and their ranks\n",
        "        player_groups = match.select('.player-row__team-wrapper')\n",
        "        if player_groups:\n",
        "            # Extract for first team\n",
        "            first_team_players = player_groups[0].select('p')\n",
        "            if len(first_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                first_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in first_team_players)\n",
        "                first_spec = ''\n",
        "            else:\n",
        "                first_names, first_spec = extract_last_name(first_team_players[0].get_text())\n",
        "\n",
        "            # Extract for second team\n",
        "            second_team_players = player_groups[1].select('p') if len(player_groups) > 1 else []\n",
        "            if len(second_team_players) > 1:\n",
        "                # Doubles match: Extract only last names\n",
        "                second_names = '/'.join(extract_last_name(p.get_text().strip())[0] for p in second_team_players)\n",
        "                second_spec = ''\n",
        "            else:\n",
        "                second_names, second_spec = extract_last_name(second_team_players[0].get_text()) if second_team_players else ('', '')\n",
        "        else:\n",
        "            first_names, second_names, first_spec, second_spec = ('', '', '', '')\n",
        "\n",
        "        first_players.append(first_names)\n",
        "        second_players.append(second_names)\n",
        "        first_special.append(first_spec)\n",
        "        second_special.append(second_spec)\n",
        "\n",
        "        genders.append(round_info.get_text().split('•')[0].strip() if round_info else '')\n",
        "        courts.append(court_name)\n",
        "        match_numbers.append(match_number)\n",
        "        match_number += 1\n",
        "\n",
        "# Step 3: Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'First Player': first_players,\n",
        "    'Second Player': second_players,\n",
        "    'Round': rounds,\n",
        "    'Time': times,\n",
        "    'Gender': genders,\n",
        "    'Court': courts,\n",
        "    'Player 1 Rank': first_special,\n",
        "    'Player 2 Rank': second_special,\n",
        "    'Match Number': match_numbers\n",
        "})\n",
        "\n",
        "# Authenticate and connect to Google Sheets\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "\n",
        "# Check if the worksheet already exists, if not, create a new one\n",
        "try:\n",
        "    worksheet = sheet.worksheet(source_worksheet_name)\n",
        "except gspread.WorksheetNotFound:\n",
        "    worksheet = sheet.add_worksheet(title=source_worksheet_name, rows=\"100\", cols=\"20\")\n",
        "\n",
        "# Convert the DataFrame to a list of lists and upload to Google Sheets\n",
        "worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "worksheet.update('J1', match_number - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fnp1OT5ckV8G"
      },
      "outputs": [],
      "source": [
        "#@title Parsing the existing times\n",
        "import re\n",
        "from datetime import datetime\n",
        "import pytz  # Ensure this is installed\n",
        "from bs4 import BeautifulSoup\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/spreadsheets\",\n",
        "         \"https://www.googleapis.com/auth/drive.file\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "sheet = client.open_by_key(sheet_id)\n",
        "worksheet = sheet.worksheet(source_worksheet_name)\n",
        "\n",
        "total_matches_script_a = int(worksheet.acell('J1').value)\n",
        "\n",
        "\n",
        "def convert_gmt_to_local_24hr(gmt_time_str):\n",
        "    \"\"\"Converts GMT time string to GMT+11 in 24-hour format and returns it.\"\"\"\n",
        "    try:\n",
        "        gmt_time = datetime.strptime(gmt_time_str, '%I:%M%p')\n",
        "        gmt_time = pytz.timezone('GMT').localize(gmt_time)\n",
        "        local_time = gmt_time.astimezone(pytz.timezone('Etc/GMT-11'))\n",
        "        return local_time.strftime('%H:%M')  # 24-hour format\n",
        "    except ValueError:\n",
        "        return ''\n",
        "\n",
        "\n",
        "# Step 1: Read the HTML file\n",
        "html_file_path = 'Scraped.html'  # Replace with your actual file path\n",
        "with open(html_file_path, 'r') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Step 2: Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# List to store extracted datetimes along with match numbers\n",
        "start_datetimes_with_numbers = []\n",
        "\n",
        "# Initialize match counter before the loop\n",
        "match_number = 1\n",
        "\n",
        "# Variable to store the current session time\n",
        "current_session_time = None\n",
        "time_assigned = False  # Flag to check if time is assigned to a session\n",
        "\n",
        "# Loop through each element in the HTML\n",
        "for element in soup.find_all(True, class_=['schedule-location__session-text', 'score-row']):\n",
        "    if 'schedule-location__session-text' in element.get('class', []):\n",
        "        # Extract the session time\n",
        "        time_text = element.get_text()\n",
        "        time_match = re.search(r'(From|Not before)\\s+(\\d+:\\d+\\w+)', time_text)\n",
        "        if time_match:\n",
        "            gmt_time = time_match.group(2)\n",
        "            local_time_24hr = convert_gmt_to_local_24hr(gmt_time)\n",
        "            current_session_time = datetime.strptime(f\"{date_input} {local_time_24hr}\", \"%Y-%m-%d %H:%M\") if local_time_24hr != '' else ''\n",
        "            time_assigned = True  # Time is assigned for this session\n",
        "        else:\n",
        "            current_session_time = ''\n",
        "            time_assigned = False  # No valid time for this session\n",
        "    elif 'score-row' in element.get('class', []):\n",
        "        # Assign the current session time to the match only if the time was assigned in the current session\n",
        "        if time_assigned:\n",
        "            start_datetimes_with_numbers.append((match_number, current_session_time))\n",
        "        else:\n",
        "            start_datetimes_with_numbers.append((match_number, ''))  # Or skip this line to not include matches without times\n",
        "\n",
        "        # Increment match counter\n",
        "        match_number += 1\n",
        "        time_assigned = False  # Reset the flag after assigning time to a match\n",
        "\n",
        "# Prepare data for writing (convert datetime objects to strings)\n",
        "data_to_write = []\n",
        "for match in start_datetimes_with_numbers:\n",
        "    # Convert datetime to string, or leave as 'N/A' if not a datetime object\n",
        "    datetime_str = match[1].strftime('%Y-%m-%d %H:%M') if isinstance(match[1], datetime) else match[1]\n",
        "    data_to_write.append([datetime_str])\n",
        "# Write data to Google Sheet starting from cell B2\n",
        "worksheet.update('D2', data_to_write)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eOxv4MZtkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Calculating the rest of the times\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def update_missing_match_times(sheet_id, source_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "    worksheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "\n",
        "    # Read the data from the sheet\n",
        "    try:\n",
        "        data = worksheet.get_all_values()\n",
        "        matches = data[1:]  # Assuming the first row is a header\n",
        "\n",
        "        current_court = None\n",
        "        current_time = None\n",
        "        previous_match_type = None  # Track the type of the previous match\n",
        "\n",
        "        for i, row in enumerate(matches):\n",
        "            existing_time_str = row[3]  # Time information in Column D\n",
        "            court = row[5]  # Court information in Column F\n",
        "            match_type = row[4]  # Match type in Column E\n",
        "\n",
        "            if existing_time_str.strip():\n",
        "                # If there is an existing time, parse it and use it as the current time\n",
        "                current_time = datetime.strptime(existing_time_str, '%Y-%m-%d %H:%M')\n",
        "            else:\n",
        "                # Skip if current_time is not set (i.e., no previous match time to base on)\n",
        "                if not current_time:\n",
        "                    continue\n",
        "\n",
        "                # Calculate the match time based on the gender information\n",
        "                duration = timedelta(hours=3) if previous_match_type == \"Men's Singles\" else timedelta(hours=2)\n",
        "                current_time += duration\n",
        "\n",
        "                # Format the date-time in an ISO format recognized by Google Sheets\n",
        "                iso_formatted_time = current_time.strftime('%Y-%m-%d %H:%M')\n",
        "\n",
        "                # Update the sheet with new value for this row\n",
        "                worksheet.update(f'D{i + 2}', [[iso_formatted_time]])  # i + 2 to write to the correct row\n",
        "\n",
        "            # Update court and previous match type for next iteration\n",
        "            current_court = court\n",
        "            previous_match_type = match_type\n",
        "\n",
        "        # Apply the desired date format to the column\n",
        "        date_format = {\"numberFormat\": {\"type\": \"DATE_TIME\", \"pattern\": \"dd/MM/yyyy HH:mm\"}}\n",
        "        worksheet.format('B2:B' + str(len(matches) + 1), date_format)\n",
        "\n",
        "        print(\"Missing match times updated successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing sheet: {e}\")\n",
        "\n",
        "# Example call to the function (replace with actual values)\n",
        "update_missing_match_times(sheet_id, source_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z_LbUXlokV8G"
      },
      "outputs": [],
      "source": [
        "#@title Setting up initial Day from template\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the source and destination Google Sheets\n",
        "    try:\n",
        "        source_sheet = client.open_by_key(template_sheet_id)\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if the destination worksheet exists, create if not\n",
        "    try:\n",
        "        dest_worksheet = None\n",
        "        try:\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create a new worksheet\n",
        "            dest_sheet.add_worksheet(title=dest_worksheet_name, rows=\"1000\", cols=\"26\")  # Adjust rows and columns as needed\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "\n",
        "        source_worksheet = source_sheet.worksheet(template_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing or creating worksheets: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the detailed data from the source sheet\n",
        "        source_range = f'{source_worksheet.title}!{sheet_range}'\n",
        "        request = service.spreadsheets().get(spreadsheetId=template_sheet_id, ranges=[source_range], includeGridData=True)\n",
        "        source_data = request.execute()\n",
        "\n",
        "        # Extract data for updating the destination sheet\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            row_data = []\n",
        "            for cell in row.get('values', []):\n",
        "                # Handle different types of values including formulas\n",
        "                if 'userEnteredValue' in cell:\n",
        "                    cell_value = cell['userEnteredValue']\n",
        "                    if 'formulaValue' in cell_value:\n",
        "                        row_data.append(cell_value['formulaValue'])\n",
        "                    elif 'stringValue' in cell_value:\n",
        "                        row_data.append(cell_value['stringValue'])\n",
        "                    elif 'numberValue' in cell_value:\n",
        "                        row_data.append(cell_value['numberValue'])\n",
        "                    elif 'boolValue' in cell_value:\n",
        "                        row_data.append(cell_value['boolValue'])\n",
        "                    else:\n",
        "                        row_data.append('')\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Extract data validation rules\n",
        "        validation_rules = []\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        for i, row in enumerate(rows):\n",
        "            for j, cell in enumerate(row.get('values', [])):\n",
        "                if 'dataValidation' in cell:\n",
        "                    rule = cell['dataValidation']\n",
        "                    validation_rules.append({\n",
        "                        'range': {\n",
        "                            'sheetId': dest_worksheet.id,\n",
        "                            'startRowIndex': i,\n",
        "                            'endRowIndex': i + 1,\n",
        "                            'startColumnIndex': j,\n",
        "                            'endColumnIndex': j + 1\n",
        "                        },\n",
        "                        'rule': rule\n",
        "                    })\n",
        "\n",
        "        # Write values and formulas to the destination sheet\n",
        "        dest_range = f'{dest_worksheet.title}!{sheet_range}'\n",
        "        body = {'values': data}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Apply data validation rules to the destination sheet\n",
        "        if validation_rules:\n",
        "            requests = [{'setDataValidation': {'range': rule['range'], 'rule': rule['rule']}} for rule in validation_rules]\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': requests}).execute()\n",
        "\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': source_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Assuming 26 columns (A to Z)\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        print(f\"Data, formulas, formatting, and data validation rules copied successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data and format copying: {e}\")\n",
        "\n",
        "copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1rJKPZA-kV8G"
      },
      "outputs": [],
      "source": [
        "#@title Copying over from match template based on amount of matches\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def adjust_formula(formula, row_offset, current_row, reference_row, same_row_columns, section_size=5):\n",
        "    \"\"\"\n",
        "    Adjust the row references in a formula by a specific offset.\n",
        "    For specific rows and columns, the formulas will reference different rows based on the logic provided.\n",
        "    \"\"\"\n",
        "    cell_ref_regex = r'([A-Z\\$]+)(\\d+)'\n",
        "\n",
        "    def adjust_match(match):\n",
        "        col_ref = match.group(1)  # Column reference\n",
        "        row_ref = int(match.group(2))  # Row reference\n",
        "        if '$' not in col_ref:  # Skip absolute row references\n",
        "            if col_ref in same_row_columns and (current_row - reference_row) % section_size == 0:\n",
        "                # For specified columns in the first row of each section, reference the same row\n",
        "                adjusted_row_ref = current_row\n",
        "            elif col_ref in same_row_columns:\n",
        "                # For specified columns in other rows, reference the first row of the section\n",
        "                adjusted_row_ref = current_row - ((current_row - reference_row) % section_size)\n",
        "            else:\n",
        "                # For other columns, adjust normally\n",
        "                adjusted_row_ref = row_ref + row_offset\n",
        "            return f'{col_ref}{adjusted_row_ref}'\n",
        "        else:\n",
        "            return f'{col_ref}{row_ref}'\n",
        "\n",
        "    adjusted_formula = re.sub(cell_ref_regex, adjust_match, formula)\n",
        "    return adjusted_formula\n",
        "\n",
        "def replicate_formatting(sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the range to copy (rows 8-11)\n",
        "    copy_range = 'A8:AK11'\n",
        "\n",
        "    # Determine the number of rows to replicate based on 'Data 1' sheet\n",
        "    data_sheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "    data_rows = len(data_sheet.get_all_values())\n",
        "    rows_to_replicate = data_rows - 3\n",
        "\n",
        "    # Get the detailed data from the range to copy, including data validation rules\n",
        "    request = service.spreadsheets().get(spreadsheetId=sheet_id, ranges=[f'{dest_worksheet.title}!{copy_range}'], includeGridData=True)\n",
        "    source_data = request.execute()\n",
        "\n",
        "    # Extract data, formulas, formats, and data validation rules for updating the destination sheet\n",
        "    source_rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "    source_data_list = []\n",
        "    data_validation_rules = []\n",
        "    for row_index, row in enumerate(source_rows):\n",
        "        row_data = []\n",
        "        row_rules = []\n",
        "        for cell_index, cell in enumerate(row.get('values', [])):\n",
        "            # Data extraction\n",
        "            if 'userEnteredValue' in cell:\n",
        "                cell_value = cell['userEnteredValue']\n",
        "                if 'formulaValue' in cell_value:\n",
        "                    row_data.append(cell_value['formulaValue'])\n",
        "                elif 'stringValue' in cell_value:\n",
        "                    row_data.append(cell_value['stringValue'])\n",
        "                elif 'numberValue' in cell_value:\n",
        "                    row_data.append(cell_value['numberValue'])\n",
        "                elif 'boolValue' in cell_value:\n",
        "                    row_data.append(cell_value['boolValue'])\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            # Data validation rule extraction\n",
        "            if 'dataValidation' in cell:\n",
        "                rule = cell['dataValidation']\n",
        "                row_rules.append((row_index, cell_index, rule))\n",
        "        source_data_list.append(row_data)\n",
        "        data_validation_rules.extend(row_rules)\n",
        "\n",
        "    # Replicate the formatting, data, and data validation rules with gaps\n",
        "    original_row_count = 4  # Number of rows in the source range (8-11)\n",
        "    start_row = 12  # Start copying from row 13, leaving a gap after row 11\n",
        "    same_row_columns = {'B','C','E','F','H','K','L','W','X','Y','Z','AC','AE','AG','AA','aa'}  # Columns that should always reference the same row\n",
        "\n",
        "    for i in range(rows_to_replicate):\n",
        "        row_offset = (original_row_count + 1) * i  # Calculate the offset for this replication\n",
        "        reference_row = start_row + 1  # The first row of the current section\n",
        "\n",
        "        # Data and formula adjustment\n",
        "        adjusted_data_list = []\n",
        "        for row_index, row in enumerate(source_data_list):\n",
        "            current_row = start_row + row_index + 1  # Calculate the current row\n",
        "            adjusted_row = []\n",
        "            for cell in row:\n",
        "                if isinstance(cell, str) and cell.startswith('='):  # Check if it's a formula\n",
        "                    adjusted_row.append(adjust_formula(cell, row_offset, current_row, reference_row, same_row_columns))\n",
        "                else:\n",
        "                    adjusted_row.append(cell)\n",
        "            adjusted_data_list.append(adjusted_row)\n",
        "\n",
        "        # Update values and formulas\n",
        "        dest_range = f'{dest_worksheet.title}!A{start_row + 1}:AK{start_row + 4}'\n",
        "        body = {'values': adjusted_data_list}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 7,\n",
        "                        'endRowIndex': 11,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Including column AK\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row,\n",
        "                        'endRowIndex': start_row + 4,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        # Apply data validation rules\n",
        "        for rule_index, (src_row, src_col, rule) in enumerate(data_validation_rules):\n",
        "            rule_request = {\n",
        "                'setDataValidation': {\n",
        "                    'range': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row + src_row,\n",
        "                        'endRowIndex': start_row + src_row + 1,\n",
        "                        'startColumnIndex': src_col,\n",
        "                        'endColumnIndex': src_col + 1,\n",
        "                    },\n",
        "                    'rule': rule\n",
        "                }\n",
        "            }\n",
        "            time.sleep(3.5)\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': [rule_request]}).execute()\n",
        "\n",
        "        # Update the starting row for the next replication\n",
        "        start_row += 5  # 4 rows of data plus 1 row gap\n",
        "\n",
        "    print(f\"Formats, data, and data validation rules replicated successfully for {rows_to_replicate} sections.\")\n",
        "\n",
        "# Call the function\n",
        "replicate_formatting(sheet_id, dest_worksheet_name, credentials_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0HolqTFKkV8G"
      },
      "outputs": [],
      "source": [
        "#@title Copying over match data from data sheet\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def transfer_data(sheet_id, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        data_worksheet = dest_sheet.worksheet(source_worksheet_name)\n",
        "        day_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the columns to transfer and their destination columns\n",
        "    columns_to_transfer = {\n",
        "        4: 'AB',  # D2 onwards to AB3 onwards - time\n",
        "        1: 'AC',  # A2 onwards to AC3 onwards - player 1\n",
        "        2: 'AE',  # B2 onwards to AE3 onwards - player 2\n",
        "        3: 'Z',   # C2 onwards to Z3 onwards - round\n",
        "        6: 'AG'   # F2 onwards to AG3 onwards - court\n",
        "    }\n",
        "\n",
        "    for source_col, dest_col_prefix in columns_to_transfer.items():\n",
        "        # Get all values from the source column starting from row 2\n",
        "        values = data_worksheet.col_values(source_col)[1:]  # Skip the first row (title)\n",
        "\n",
        "        # Loop through the values\n",
        "        for i, value in enumerate(values, start=1):\n",
        "            # Calculate the destination row using the formula\n",
        "            dest_row = 3 + (i - 1) * 5\n",
        "\n",
        "            # Write the value to the calculated cell in 'Day 1'\n",
        "            time.sleep(2)\n",
        "            day_worksheet.update_acell(f'{dest_col_prefix}{dest_row}', value)\n",
        "        print(f\"Data from column {source_col} transferred to column {dest_col_prefix} for {len(values)} rows.\")\n",
        "\n",
        "# Call the function\n",
        "transfer_data(sheet_id, credentials_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tennis Pre-Images:**"
      ],
      "metadata": {
        "id": "xXc54Z0NGYdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Selenium\n",
        "\n",
        "# Set up for running selenium in Google Colab\n",
        "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium\n",
        "pip install webdriver-manager"
      ],
      "metadata": {
        "id": "tkxfh3neK5Eg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Flags folder from Dropbox\n",
        "\n",
        "!wget -O Flags.zip \"https://www.dropbox.com/scl/fo/z2ao7680uo1avlxry68zg/h?rlkey=0yr70n4b7v3ol37jyhmbfflnh&dl=0\"\n",
        "!mkdir -p Flags\n",
        "!unzip Flags.zip -d Flags\n",
        "!rm Flags.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "t5y0TVfrGd87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Tennis Prepromotes (COMMENTARY)**\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException, ElementClickInterceptedException\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.service_account import Credentials\n",
        "\n",
        "folder_name = 'Prepromotes'\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "download_default_directory = f'/content/{folder_name}'\n",
        "\n",
        "#logos image input\n",
        "logos_base_path = '/content/Flags'\n",
        "\n",
        "# Google Sheets API setup\n",
        "creds = Credentials.from_service_account_file('/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0')\n",
        "service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "# Your Google Sheet ID and the range of cells to access\n",
        "SPREADSHEET_ID = '1st-aXLd3iuAegiXiGFRxeW2Oewbh7tp9GZl1fQCQIv8' #@param {type:\"string\"}\n",
        "RANGE_NAME = 'Tilebot!A1:M200'\n",
        "tennis = 'Australian Open' # @param [\"Australian Open\", \"United Cup\", \"Brisbane International 2024\", \"Adelaide International\"]\n",
        "\n",
        "live_and_upcoming = True # @param {type:\"boolean\"}\n",
        "prematch_logo_card = False # @param {type:\"boolean\"}\n",
        "postmatch_logo_card = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Set up headless Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_experimental_option(\"prefs\", {\n",
        "  \"download.default_directory\": f'/content/{folder_name}',\n",
        "  \"download.prompt_for_download\": False,\n",
        "  \"download.directory_upgrade\": True,\n",
        "  \"safebrowsing.enabled\": True\n",
        "})\n",
        "\n",
        "# Call the Sheets API to read data\n",
        "sheet_service = service.spreadsheets()\n",
        "result = sheet_service.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
        "values = result.get('values', [])\n",
        "\n",
        "# Function to clear input field\n",
        "def clear_input_field(element):\n",
        "    # Clear using Selenium's clear method\n",
        "    element.clear()\n",
        "    # If the element is not cleared, use JavaScript to clear it\n",
        "    browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "    # Check and retry if the input is not cleared\n",
        "    for i in range(3):\n",
        "        if element.get_attribute('value'):\n",
        "            element.clear()\n",
        "            browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "def wait_for_download_complete(download_directory, timeout=300):\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        # Find the most recent zip file in the directory\n",
        "        zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')],\n",
        "                           key=lambda f: os.path.getctime(os.path.join(download_directory, f)),\n",
        "                           reverse=True)\n",
        "\n",
        "        if zip_files:\n",
        "            latest_zip = os.path.join(download_directory, zip_files[0])\n",
        "            initial_size = os.path.getsize(latest_zip)\n",
        "\n",
        "            # Wait for a short period to check if the file is still being written to\n",
        "            time.sleep(1)\n",
        "            if os.path.getsize(latest_zip) == initial_size:\n",
        "                # If file size hasn't changed, assume download is complete\n",
        "                return latest_zip\n",
        "\n",
        "        # Check for timeout\n",
        "        if (time.time() - start_time) > timeout:\n",
        "            raise Exception(\"Timeout: File download did not complete within the specified time.\")\n",
        "\n",
        "        time.sleep(1)  # Check every 1 second\n",
        "\n",
        "# Create a browser instance with headless Chrome\n",
        "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "browser.set_window_size(1920, 1080)\n",
        "\n",
        "# Process and iterate over Google Sheets data\n",
        "if not values:\n",
        "    print('No data found.')\n",
        "else:\n",
        "    for row in values:\n",
        "        # Ensure row has enough elements\n",
        "        row += [None] * (14 - len(row))\n",
        "\n",
        "        # Unpack the row into variables\n",
        "        input1_value, firstname1_value, countries1_value, input2_value, firstname2_value, countries2_value, datetime_value, round_value, gender_value, sd_value, rank1_value, rank2_value, event_data, movida_value = row\n",
        "\n",
        "        if input1_value is None:  # Check for end of data\n",
        "            break\n",
        "\n",
        "        browser.get('https://thelivecms.prod.streamco.cloud/tile-creator/')\n",
        "            # live & upcoming\n",
        "\n",
        "        if live_and_upcoming:\n",
        "          live = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Live & Upcoming')]\")\n",
        "              )\n",
        "          )\n",
        "          live.click();\n",
        "\n",
        "        # home & away\n",
        "        if live_and_upcoming:\n",
        "          home = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Home v Away (tennis, combat, football, etc)')]\")\n",
        "              )\n",
        "          )\n",
        "          home.click()\n",
        "\n",
        "        # logo cards\n",
        "\n",
        "        logo = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH,  \"//*[contains(text(), 'Logo Cards')]\")\n",
        "            )\n",
        "        )\n",
        "        logo.click();\n",
        "\n",
        "        # prematch logo card\n",
        "        if prematch_logo_card:\n",
        "          pre = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Logo Card Prematch')]\")\n",
        "              )\n",
        "          )\n",
        "          pre.click()\n",
        "\n",
        "        # postmatch logo card\n",
        "        if postmatch_logo_card:\n",
        "          post = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Logo Card Postmatch')]\")\n",
        "              )\n",
        "          )\n",
        "          post.click()\n",
        "\n",
        "        # select sport + competition\n",
        "\n",
        "        select1 = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.ID, \"select-sport-type-id\")\n",
        "            )\n",
        "        )\n",
        "        select1 = Select(select1)\n",
        "        select1.select_by_visible_text('Tennis')\n",
        "\n",
        "        select2 = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.ID, \"select-competition-id\")\n",
        "            )\n",
        "        )\n",
        "        select2 = Select(select2)\n",
        "\n",
        "        # Implementing the conditional logic\n",
        "        if tennis == 'Australian Open':\n",
        "            if sd_value == 'Singles':\n",
        "                select2.select_by_visible_text('TENNIS: Australian Open Singles')\n",
        "            else:\n",
        "                select2.select_by_visible_text('TENNIS: Australian Open Extra Comps')\n",
        "        # You can add more conditions for other tennis values\n",
        "        else:\n",
        "            selection_text = f'TENNIS: {tennis}'\n",
        "            select2.select_by_visible_text(selection_text)\n",
        "\n",
        "        # Enabling 4 players\n",
        "        if sd_value == 'Doubles':\n",
        "            fourplayers_checkbox = WebDriverWait(browser, 2, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.XPATH,  \"//label[text()='4 Players']/preceding-sibling::input\")\n",
        "                )\n",
        "            )\n",
        "            fourplayers_checkbox.click()\n",
        "\n",
        "        # Inputting the first name no.1\n",
        "\n",
        "        if sd_value == 'Singles':\n",
        "            firstname1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #1 Small text')]/following-sibling::input[@type='text']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(firstname1)\n",
        "\n",
        "            firstname1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #1 Small text')]/following-sibling::input[@type='text']\")\n",
        "                )\n",
        "            )\n",
        "            firstname1.send_keys(firstname1_value)\n",
        "\n",
        "            # Inputting the first name no.2\n",
        "\n",
        "            firstname2 = browser.find_element(By.XPATH, \"//label[contains(text(), 'Opponent #2 Small text')]/following-sibling::input[@type='text']\")\n",
        "            clear_input_field(firstname2)\n",
        "            firstname2.send_keys(firstname2_value)\n",
        "\n",
        "\n",
        "        if '/' in input1_value:\n",
        "            # Split the string into two parts at the slash\n",
        "            name1_value, name2_value = input1_value.split('/')\n",
        "\n",
        "            # name 1\n",
        "\n",
        "            name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(name1)\n",
        "            time.sleep(2)\n",
        "\n",
        "            name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "                )\n",
        "            )\n",
        "            name1.send_keys(name1_value)\n",
        "\n",
        "            # name 2\n",
        "            name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='home2']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(name2)\n",
        "\n",
        "            name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='home2']\")\n",
        "                )\n",
        "            )\n",
        "            name2.send_keys(name2_value)\n",
        "\n",
        "            # Now name1 and name2 hold the separate names\n",
        "            # You can use name1 and name2 as needed in your code\n",
        "        else:\n",
        "            input1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.ID, \"downshift-0-input\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(input1)\n",
        "\n",
        "            input1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.ID, \"downshift-0-input\")\n",
        "                )\n",
        "            )\n",
        "            input1.send_keys(input1_value)\n",
        "\n",
        "            # team 2\n",
        "\n",
        "            input2 = browser.find_element(By.ID,\"downshift-1-input\")\n",
        "            clear_input_field(input2)\n",
        "            input2.send_keys(input2_value)\n",
        "\n",
        "\n",
        "        if '/' in input2_value:\n",
        "            # Split the string into two parts at the slash\n",
        "            name3_value, name4_value = input2_value.split('/')\n",
        "\n",
        "            name3 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(name3)\n",
        "\n",
        "            name3 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "                )\n",
        "            )\n",
        "            name3.send_keys(name3_value)\n",
        "\n",
        "            name4 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='away2']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(name4)\n",
        "\n",
        "            name4 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[value='away2']\")\n",
        "                )\n",
        "            )\n",
        "            name4.send_keys(name4_value)\n",
        "\n",
        "        # rank 1\n",
        "\n",
        "        if sd_value == 'Singles':\n",
        "            if rank1_value:  # This will be False if rank1_value is blank or None\n",
        "                rank1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                    EC.element_to_be_clickable(\n",
        "                        (By.XPATH, \"//label[contains(text(), 'Opponent #1 Rank')]/following-sibling::input[@type='text']\")\n",
        "                    )\n",
        "                )\n",
        "                rank1.send_keys(rank1_value)\n",
        "\n",
        "        # rank 2\n",
        "        if sd_value == 'Singles':\n",
        "            if rank2_value:  # This will be False if rank1_value is blank or None\n",
        "                rank2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "                    EC.element_to_be_clickable(\n",
        "                        (By.XPATH, \"//label[contains(text(), 'Opponent #2 Rank')]/following-sibling::input[@type='text']\")\n",
        "                    )\n",
        "                )\n",
        "                rank2.send_keys(rank2_value)\n",
        "\n",
        "        # rank2 = browser.find_element(By.XPATH, \"//label[contains(text(), 'Opponent #2 Rank')]/following-sibling::input[@type='text']\")\n",
        "        # clear_input_field(rank2)\n",
        "        # rank2.send_keys(rank2_value)\n",
        "\n",
        "        if '/' in countries1_value:\n",
        "            # Split the string into two parts at the slash\n",
        "            country1_value, country2_value = countries1_value.split('/')\n",
        "\n",
        "            # opponent 1A flag\n",
        "            file_input_opponent1A = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #1A Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent1A = os.path.join(logos_base_path, f\"{country1_value}.png\")\n",
        "            file_input_opponent1A.send_keys(file_path_opponent1A)\n",
        "\n",
        "            # opponent 1B flag\n",
        "            file_input_opponent1B = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #1B Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent1B = os.path.join(logos_base_path, f\"{country2_value}.png\")\n",
        "            file_input_opponent1B.send_keys(file_path_opponent1B)\n",
        "\n",
        "\n",
        "        else:\n",
        "            # opponent 1 flag\n",
        "            file_input_opponent1 = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #1 Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent1 = os.path.join(logos_base_path, f\"{countries1_value}.png\")\n",
        "            file_input_opponent1.send_keys(file_path_opponent1)\n",
        "\n",
        "            # opponent 2 flag\n",
        "            file_input_opponent2 = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #2 Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent2 = os.path.join(logos_base_path, f\"{countries2_value}.png\")\n",
        "            file_input_opponent2.send_keys(file_path_opponent2)\n",
        "\n",
        "        if '/' in countries2_value:\n",
        "            # Split the string into two parts at the slash\n",
        "            country3_value, country4_value = countries2_value.split('/')\n",
        "\n",
        "            # opponent 2A flag\n",
        "            file_input_opponent2A = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #2A Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent2A = os.path.join(logos_base_path, f\"{country3_value}.png\")\n",
        "            file_input_opponent2A.send_keys(file_path_opponent2A)\n",
        "\n",
        "            # opponent 2B flag\n",
        "            file_input_opponent2B = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH, \"//label[contains(text(), 'Opponent #2B Flag')]/following-sibling::input[@type='file']\")\n",
        "                )\n",
        "            )\n",
        "            file_path_opponent2B = os.path.join(logos_base_path, f\"{country4_value}.png\")\n",
        "            file_input_opponent2B.send_keys(file_path_opponent2B)\n",
        "\n",
        "\n",
        "        # delete event long\n",
        "\n",
        "        event_long = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='Event Long']\")\n",
        "            )\n",
        "        )\n",
        "        clear_input_field(event_long)\n",
        "\n",
        "        # if event_data:  # Check if event_data is not empty\n",
        "        #     event_long.send_keys(event_data)\n",
        "        # else:  # If event_data is empty or None\n",
        "        #     event_long.send_keys(\" \")\n",
        "\n",
        "        if sd_value == 'Singles':\n",
        "            if event_data:  # Check if event_data is not empty\n",
        "                event_long.send_keys(event_data)\n",
        "            else:  # If event_data is empty or None\n",
        "                event_long.send_keys(\" \")\n",
        "\n",
        "        elif sd_value == 'Doubles':\n",
        "            if event_data:  # Check if event_data is not empty\n",
        "                event_long.send_keys(event_data)\n",
        "            else:  # If event_data is empty or None\n",
        "                event_long.send_keys(f\"{gender_value} {sd_value}\")\n",
        "\n",
        "        # date (e.g Nov 6)\n",
        "        # Example string, replace with your actual date string format\n",
        "        datetime_str = datetime_value  # Assuming the format is something like 'YYYY-MM-DD'\n",
        "\n",
        "        # Convert the string to a datetime object\n",
        "        datetime_obj = datetime.strptime(datetime_str, '%d/%m/%Y %H:%M')\n",
        "\n",
        "\n",
        "        if postmatch_logo_card:\n",
        "          date_input = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.XPATH, \"//input[@placeholder='competition date']\")\n",
        "              )\n",
        "          )\n",
        "          date_input = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='competition date']\"))\n",
        "          )\n",
        "          clear_input_field(date_input)\n",
        "          desired_date = datetime_obj.strftime('%b %-d')\n",
        "          date_input.send_keys(desired_date)\n",
        "\n",
        "        # round\n",
        "\n",
        "        round_textarea = WebDriverWait(browser, 10).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//label[contains(text(), 'Round')]/following-sibling::textarea\"))\n",
        "        )\n",
        "        clear_input_field(round_textarea)\n",
        "        # round_textarea.send_keys(f\"{round_value}\")\n",
        "        # if sd_value == 'Doubles':\n",
        "        #     round_textarea.send_keys(f\"{gender_value} {sd_value} {round_value}\")\n",
        "        # else:\n",
        "        #     round_textarea.send_keys(f\"{gender_value} {round_value}\")\n",
        "        if sd_value == 'Doubles':\n",
        "            if event_data:  # Check if event_data is not empty\n",
        "                round_textarea.send_keys(f\"{gender_value} {sd_value} {round_value}\")\n",
        "            else:  # If event_data is empty or None\n",
        "                round_textarea.send_keys(f\"{round_value}\")\n",
        "        else:\n",
        "            round_textarea.send_keys(f\"{gender_value} {round_value}\")\n",
        "\n",
        "        # comp - flag\n",
        "\n",
        "        # select4 = WebDriverWait(browser, 2, 0.2).until(\n",
        "        #     EC.presence_of_element_located(\n",
        "        #         (By.ID, \"select-special-carousel-logo-id\")\n",
        "        #     )\n",
        "        # )\n",
        "        # select4 = Select(select4)\n",
        "        # select4.select_by_visible_text('TENNIS: US Open Extras')\n",
        "        if postmatch_logo_card:\n",
        "          select4_input = WebDriverWait(browser, 10).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH, \"//label[contains(text(), 'Carousel Logo')]/following-sibling::input[@type='file']\")\n",
        "              )\n",
        "          )\n",
        "          # Mapping the competition names to file paths\n",
        "          file_paths = {\n",
        "              \"United Cup\": '/content/Flags/United Cup.png',\n",
        "              \"Australian Open\": '/content/Flags/Australian Open.png',\n",
        "              \"Brisbane International 2024\": '/content/Flags/Brisbane International.png',\n",
        "              \"Adelaide International\": '/content/Flags/Adelaide International.png'\n",
        "          }\n",
        "          select4_path = file_paths[tennis]\n",
        "          select4_input.send_keys(select4_path)\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "        # downloading\n",
        "\n",
        "        try:\n",
        "            # Wait for the button to be clickable by both class and text, with a timeout of 10 seconds\n",
        "            save_as_zip_button = WebDriverWait(browser, 10).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-warning') and contains(text(), 'Save as .zip')]\"))\n",
        "            )\n",
        "            time.sleep(5)\n",
        "\n",
        "            # Instead of clicking the button with Selenium's click function, we use JavaScript to click\n",
        "            browser.execute_script(\"arguments[0].click();\", save_as_zip_button)\n",
        "            print(\"Button clicked successfully via JavaScript.\")\n",
        "        except TimeoutException:\n",
        "            print(\"Button was not found within the given time.\")\n",
        "        except NoSuchElementException:\n",
        "            print(\"Button could not be found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "        download_directory = download_default_directory\n",
        "        try:\n",
        "            downloaded_file = wait_for_download_complete(download_directory)\n",
        "            print(f\"Download complete: {downloaded_file}\")\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "        zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')], key=lambda f: os.path.getctime(os.path.join(download_directory, f)), reverse=True)\n",
        "\n",
        "        if sd_value == 'Singles':\n",
        "            if zip_files:\n",
        "                zip_file_name = zip_files[0]\n",
        "                zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(download_directory)\n",
        "                    extracted_files = zip_ref.namelist()\n",
        "\n",
        "                if extracted_files:\n",
        "                    new_singles_folder_path = os.path.join(download_directory, f\"{input1_value} v {input2_value} {gender_value} {sd_value}\")\n",
        "                    if not os.path.exists(new_singles_folder_path):\n",
        "                        os.mkdir(new_singles_folder_path)\n",
        "\n",
        "                    print(f\"Moving files to {new_singles_folder_path}\")\n",
        "\n",
        "                    for file in extracted_files:\n",
        "                        original_file_path = os.path.join(download_directory, file)\n",
        "                        new_file_path = os.path.join(new_singles_folder_path, file)\n",
        "                        # print(f\"Moving {original_file_path} to {new_file_path}\")\n",
        "                        shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "                    subprocess.run([\"open\", \"-R\", new_singles_folder_path])\n",
        "\n",
        "                else:\n",
        "                    print(\"No files found in the zip.\")\n",
        "            else:\n",
        "                print(\"No zip files found in the download directory.\")\n",
        "\n",
        "            os.remove(zip_file_path)\n",
        "        else:\n",
        "            name1_value, name2_value = input1_value.split('/')\n",
        "            name3_value, name4_value = input2_value.split('/')\n",
        "            if zip_files:\n",
        "                zip_file_name = zip_files[0]\n",
        "                zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "                with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(download_directory)\n",
        "                    extracted_files = zip_ref.namelist()\n",
        "\n",
        "                if extracted_files:\n",
        "                    new_doubles_folder_path = os.path.join(download_directory, f\"{name1_value} v {name3_value} {sd_value}\")\n",
        "                    if not os.path.exists(new_doubles_folder_path):\n",
        "                        os.mkdir(new_doubles_folder_path)\n",
        "\n",
        "                    print(f\"Moving files to {new_doubles_folder_path}\")\n",
        "\n",
        "                    for file in extracted_files:\n",
        "                        original_file_path = os.path.join(download_directory, file)\n",
        "                        new_file_path = os.path.join(new_doubles_folder_path, file)\n",
        "                        # print(f\"Moving {original_file_path} to {new_file_path}\")\n",
        "                        shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "                    subprocess.run([\"open\", \"-R\", new_doubles_folder_path])\n",
        "\n",
        "                else:\n",
        "                    print(\"No files found in the zip.\")\n",
        "            else:\n",
        "                print(\"No zip files found in the download directory.\")\n",
        "\n",
        "            os.remove(zip_file_path)\n",
        "\n",
        "\n",
        "        # For Australian Open, process the second iteration with \"RAIN DELAY\"\n",
        "        if tennis == 'Australian Open':\n",
        "            rain_delay_input = WebDriverWait(browser, 10, 0.2).until(\n",
        "                EC.element_to_be_clickable(\n",
        "                    (By.CSS_SELECTOR, \"input[placeholder='rain delay']\")\n",
        "                )\n",
        "            )\n",
        "            clear_input_field(rain_delay_input)  # Assuming you have a function to clear the input field\n",
        "            rain_delay_input.send_keys(\"RAIN DELAY\")\n",
        "\n",
        "            try:\n",
        "                # Wait for the button to be clickable by both class and text, with a timeout of 10 seconds\n",
        "                save_as_zip_button = WebDriverWait(browser, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-warning') and contains(text(), 'Save as .zip')]\"))\n",
        "                )\n",
        "                time.sleep(5)\n",
        "\n",
        "                # Instead of clicking the button with Selenium's click function, we use JavaScript to click\n",
        "                browser.execute_script(\"arguments[0].click();\", save_as_zip_button)\n",
        "                print(\"Button clicked successfully via JavaScript.\")\n",
        "            except TimeoutException:\n",
        "                print(\"Button was not found within the given time.\")\n",
        "            except NoSuchElementException:\n",
        "                print(\"Button could not be found.\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred: {e}\")\n",
        "            download_directory = download_default_directory\n",
        "            try:\n",
        "                downloaded_file = wait_for_download_complete(download_directory)\n",
        "                print(f\"Download complete: {downloaded_file}\")\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "\n",
        "            zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')], key=lambda f: os.path.getctime(os.path.join(download_directory, f)), reverse=True)\n",
        "            if zip_files:\n",
        "              zip_file_name = zip_files[0]\n",
        "              zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "              # Verify the zip file before attempting to extract\n",
        "              if os.path.isfile(zip_file_path) and os.path.getsize(zip_file_path) > 0:\n",
        "                  with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                      try:\n",
        "                          zip_ref.extractall(download_directory)\n",
        "                          extracted_files = zip_ref.namelist()\n",
        "                          print(f\"Extracted files: {extracted_files}\")\n",
        "                      except zipfile.BadZipFile:\n",
        "                          print(f\"Failed to extract {zip_file_path}: The file may be corrupted.\")\n",
        "                      except Exception as e:\n",
        "                          print(f\"An unexpected error occurred while extracting {zip_file_path}: {e}\")\n",
        "              else:\n",
        "                  print(f\"The zip file {zip_file_path} does not exist or is empty.\")\n",
        "\n",
        "            if sd_value == 'Singles':\n",
        "                folder_path = new_singles_folder_path\n",
        "            else:\n",
        "                folder_path = new_doubles_folder_path\n",
        "\n",
        "            # Create a \"Rain Delay\" subfolder inside the existing folder\n",
        "            rain_delay_folder_path = os.path.join(folder_path, \"Rain Delay\")\n",
        "            if not os.path.exists(rain_delay_folder_path):\n",
        "                os.mkdir(rain_delay_folder_path)\n",
        "\n",
        "            # Move files to the \"Rain Delay\" subfolder\n",
        "            for file in extracted_files:\n",
        "                original_file_path = os.path.join(download_directory, file)\n",
        "                new_file_path = os.path.join(rain_delay_folder_path, file)\n",
        "                shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "            os.remove(zip_file_path)\n",
        "\n",
        "browser.quit()"
      ],
      "metadata": {
        "id": "9v8wlTJXc_8k",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading\n",
        "\n",
        "folder_path = folder_name  # replace with your folder path\n",
        "zip_file = f'{folder_name}.zip'  # name of the resulting zip file\n",
        "\n",
        "# Compress the folder\n",
        "os.system(f'zip -r {zip_file} {folder_path}')\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file)"
      ],
      "metadata": {
        "id": "z7H0y2Z4O1Ij",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Deleting things\n",
        "\n",
        "import shutil\n",
        "\n",
        "dir_path = 'Prepromotes'\n",
        "\n",
        "# Remove the directory along with all its contents\n",
        "shutil.rmtree(dir_path)\n"
      ],
      "metadata": {
        "id": "pPpySyIQGk5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AO Players Scraping:**"
      ],
      "metadata": {
        "id": "ypKS8R_OGJSk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ml_fkZd277mq"
      },
      "outputs": [],
      "source": [
        "#@title Enter the URL to Scrape\n",
        "url_to_scrape = \"https://ausopen.com/players\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bvd0Jnn_77mq"
      },
      "outputs": [],
      "source": [
        "#@title Writing scraping instructions in index.js file (REAL ONE)\n",
        "\n",
        "%%writefile index.js\n",
        "'use strict';\n",
        "\n",
        "const puppeteer = require('puppeteer');\n",
        "\n",
        "const fs = require('fs');\n",
        "\n",
        "async function goPuppeteer(url) {\n",
        "  try {\n",
        "    const browser = await puppeteer.launch({\n",
        "      headless: \"new\",\n",
        "      args: ['--no-sandbox', '--disable-gpu']\n",
        "    });\n",
        "    const page = await browser.newPage();\n",
        "    await page.goto(url, {\n",
        "      waitUntil: 'load',\n",
        "      timeout: 0\n",
        "    });\n",
        "    await new Promise(resolve => setTimeout(resolve, 4000));\n",
        "\n",
        "    const htmlContent = await page.content();\n",
        "    fs.writeFileSync('Players.html', htmlContent);\n",
        "    console.log(`Content saved from ${url}`);\n",
        "\n",
        "    await browser.close();\n",
        "  } catch (e) {\n",
        "    console.error(\"Error occurred:\", e);\n",
        "  }\n",
        "}\n",
        "\n",
        "// The first two elements of process.argv array are 'node' and the script name, so the third element (index 2) is the first argument.\n",
        "const url = process.argv[2];\n",
        "goPuppeteer(url);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLW1uWMP77mq"
      },
      "outputs": [],
      "source": [
        "#@title Running index.js file\n",
        "!node index.js \"$url_to_scrape\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "txmfJu6ZefmK"
      },
      "outputs": [],
      "source": [
        "#@title Converting to CSV\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import re  # Import the regular expressions library\n",
        "\n",
        "\n",
        "def get_text_safe(element):\n",
        "    return element.get_text().strip() if element else \"Not Specified\"\n",
        "\n",
        "# Read HTML file\n",
        "file_path = '/content/Players.html'\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Parse the HTML\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# List to hold all player data\n",
        "players_data = []\n",
        "\n",
        "# Parsing detailed player information\n",
        "detailed_players = soup.find_all('li', class_='player-list-featured__list-item--two-column')\n",
        "for player in detailed_players:\n",
        "    first_name, last_name = \"Not Found\", \"Not Found\"\n",
        "    player_info = player.find('h3', class_='player-card-visual__title')\n",
        "    if player_info:\n",
        "        player_names = player_info.get_text().split()\n",
        "        first_name = player_names[0].capitalize()\n",
        "        last_name = player_names[1].capitalize() if len(player_names) > 1 else \"Not Found\"\n",
        "\n",
        "    country = get_text_safe(player.find('span', class_='player-country-flag__country')).capitalize()\n",
        "    rank = get_text_safe(player.find('div', class_='player-card-visual__rank'))\n",
        "\n",
        "    players_data.append((first_name, last_name, country, rank))\n",
        "\n",
        "# Parsing simpler player information\n",
        "simple_players = soup.find_all('li', class_='player-list__list-item')\n",
        "for player in simple_players:\n",
        "    link = player.find('a')\n",
        "    if link and 'href' in link.attrs:\n",
        "        href = link['href']\n",
        "        parts = href.split('/')\n",
        "\n",
        "        # Extract name\n",
        "        name_parts = parts[-1].split('-')\n",
        "        first_name = name_parts[0].capitalize()\n",
        "        last_name = '-'.join(name_parts[1:]).capitalize() if len(name_parts) > 1 else \"Not Found\"\n",
        "\n",
        "        # Extract country from the URL\n",
        "        country = parts[4].capitalize() if len(parts) > 5 else \"Not Specified\"\n",
        "\n",
        "        # Check if country needs to be extracted from flag image URL\n",
        "        if len(country) != 2:  # Assuming country codes are 2 letters\n",
        "            flag_span = player.find('span', class_='player-flag-2021')\n",
        "            if flag_span and 'style' in flag_span.attrs:\n",
        "                style = flag_span['style']\n",
        "                country_match = re.search(r'/([a-z]+)-empty\\.svg', style, re.IGNORECASE)\n",
        "                if country_match:\n",
        "                    country_code = country_match.group(1)\n",
        "                    country = country_code.upper()\n",
        "\n",
        "        rank = \"Not Specified\"\n",
        "        players_data.append((first_name, last_name, country, rank))\n",
        "\n",
        "\n",
        "# Specify the CSV file name\n",
        "csv_file_name = 'players_data.csv'\n",
        "\n",
        "# Write data to CSV\n",
        "with open(csv_file_name, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['First Name', 'Last Name', 'Country', 'Rank'])\n",
        "    for player in players_data:\n",
        "        writer.writerow(player)\n",
        "\n",
        "print(f\"Data written to {csv_file_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Super Rugby Pacific Pre-Images:**"
      ],
      "metadata": {
        "id": "1H_ALTHvX-nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Selenium\n",
        "\n",
        "# Set up for running selenium in Google Colab\n",
        "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium\n",
        "pip install webdriver-manager"
      ],
      "metadata": {
        "id": "jOo6zgDpX-nq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Flags folder from Dropbox\n",
        "\n",
        "# !wget -O Flags.zip \"https://www.dropbox.com/scl/fo/das3srng2au5w1jo6zi2g/h?rlkey=4tbpxjbxf9dj8081u5vknhrkm&dl=0\" HOSPITAL CUP\n",
        "!wget -O Flags.zip \"https://www.dropbox.com/scl/fo/739udyn8i2dn6xhv7yjw3/h?rlkey=yq6o1h1fzx7veo01ce8ph6uls&dl=0\"\n",
        "\n",
        "!mkdir -p Flags\n",
        "!unzip Flags.zip -d Flags\n",
        "!rm Flags.zip"
      ],
      "metadata": {
        "id": "Tjs3AjyVX-nq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Logos Folder from Dropbox\n",
        "\n",
        "!wget -O Logos.zip \"https://www.dropbox.com/scl/fo/17v400uls31pak9vm2rqp/h?rlkey=socex8uazv4fy62xnq64nmosk&dl=0\"\n",
        "\n",
        "!mkdir -p Logos\n",
        "!unzip Logos.zip -d Logos\n",
        "!rm Logos.zip"
      ],
      "metadata": {
        "id": "bpDGcth851fs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Prepromotes**\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException, ElementClickInterceptedException\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.service_account import Credentials\n",
        "\n",
        "folder_name = 'Prepromotes'\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "download_default_directory = f'/content/{folder_name}'\n",
        "\n",
        "#logos image input\n",
        "logos_base_path = '/content/Flags'\n",
        "\n",
        "# Google Sheets API setup\n",
        "creds = Credentials.from_service_account_file('/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0')\n",
        "service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "# Your Google Sheet ID and the range of cells to access\n",
        "SPREADSHEET_ID = '1nyXHaiXebmUhAXcqIaM0MCT3PjBcyGDgnQozyzu1gzA' #@param {type:\"string\"}\n",
        "RANGE_NAME = 'Tilebot!A1:M200'\n",
        "\n",
        "rugby = 'Shute Shield' # @param [\"Shute Shield\", \"Hospital Cup\", \"Oceania Rugby\"]\n",
        "\n",
        "\n",
        "live_and_upcoming = True # @param {type:\"boolean\"}\n",
        "prematch_logo_card = True # @param {type:\"boolean\"}\n",
        "postmatch_logo_card = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Set up headless Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_experimental_option(\"prefs\", {\n",
        "  \"download.default_directory\": f'/content/{folder_name}',\n",
        "  \"download.prompt_for_download\": False,\n",
        "  \"download.directory_upgrade\": True,\n",
        "  \"safebrowsing.enabled\": True\n",
        "})\n",
        "\n",
        "# Call the Sheets API to read data\n",
        "sheet_service = service.spreadsheets()\n",
        "result = sheet_service.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
        "values = result.get('values', [])\n",
        "\n",
        "# Function to clear input field\n",
        "def clear_input_field(element):\n",
        "    # Clear using Selenium's clear method\n",
        "    element.clear()\n",
        "    # If the element is not cleared, use JavaScript to clear it\n",
        "    browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "    # Check and retry if the input is not cleared\n",
        "    for i in range(3):\n",
        "        if element.get_attribute('value'):\n",
        "            element.clear()\n",
        "            browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "def wait_for_download_complete(download_directory, timeout=300):\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        # Find the most recent zip file in the directory\n",
        "        zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')],\n",
        "                           key=lambda f: os.path.getctime(os.path.join(download_directory, f)),\n",
        "                           reverse=True)\n",
        "\n",
        "        if zip_files:\n",
        "            latest_zip = os.path.join(download_directory, zip_files[0])\n",
        "            initial_size = os.path.getsize(latest_zip)\n",
        "\n",
        "            # Wait for a short period to check if the file is still being written to\n",
        "            time.sleep(1)\n",
        "            if os.path.getsize(latest_zip) == initial_size:\n",
        "                # If file size hasn't changed, assume download is complete\n",
        "                return latest_zip\n",
        "\n",
        "        # Check for timeout\n",
        "        if (time.time() - start_time) > timeout:\n",
        "            raise Exception(\"Timeout: File download did not complete within the specified time.\")\n",
        "\n",
        "        time.sleep(1)  # Check every 1 second\n",
        "\n",
        "# Create a browser instance with headless Chrome\n",
        "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Process and iterate over Google Sheets data\n",
        "if not values:\n",
        "    print('No data found.')\n",
        "else:\n",
        "    for row in values:\n",
        "        # Ensure row has enough elements\n",
        "        row += [None] * (6 - len(row))\n",
        "\n",
        "        # Unpack the row into variables\n",
        "        no_value, datetime_value, input1_value, input2_value, round_value, time_value = row\n",
        "\n",
        "        if input1_value is None:  # Check for end of data\n",
        "            break\n",
        "\n",
        "        browser.get('https://thelivecms.prod.streamco.cloud/tile-creator/')\n",
        "            # live & upcoming\n",
        "\n",
        "        if live_and_upcoming:\n",
        "          live = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Live & Upcoming')]\")\n",
        "              )\n",
        "          )\n",
        "          live.click();\n",
        "\n",
        "        # home & away\n",
        "        if live_and_upcoming:\n",
        "          home = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Home v Away (tennis, combat, football, etc)')]\")\n",
        "              )\n",
        "          )\n",
        "          home.click()\n",
        "\n",
        "        # logo cards\n",
        "\n",
        "        logo = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH,  \"//*[contains(text(), 'Logo Cards')]\")\n",
        "            )\n",
        "        )\n",
        "        logo.click();\n",
        "\n",
        "        # prematch logo card\n",
        "        if prematch_logo_card:\n",
        "          pre = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Logo Card Prematch')]\")\n",
        "              )\n",
        "          )\n",
        "          pre.click()\n",
        "\n",
        "        # postmatch logo card\n",
        "        if postmatch_logo_card:\n",
        "          post = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Logo Card Postmatch')]\")\n",
        "              )\n",
        "          )\n",
        "          post.click()\n",
        "\n",
        "        # select sport + competition\n",
        "\n",
        "        select1 = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.ID, \"select-sport-type-id\")\n",
        "            )\n",
        "        )\n",
        "        select1 = Select(select1)\n",
        "        select1.select_by_visible_text('Rugby')\n",
        "\n",
        "        select2 = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.ID, \"select-competition-id\")\n",
        "            )\n",
        "        )\n",
        "        select2 = Select(select2)\n",
        "\n",
        "        selection_text = f'RUGBY: {rugby}'\n",
        "        select2.select_by_visible_text(selection_text)\n",
        "\n",
        "        # name 1\n",
        "\n",
        "        name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "            )\n",
        "        )\n",
        "        clear_input_field(name1)\n",
        "        time.sleep(2)\n",
        "\n",
        "        name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "            )\n",
        "        )\n",
        "        name1.send_keys(input1_value)\n",
        "\n",
        "        # name 2\n",
        "        name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "            )\n",
        "        )\n",
        "        clear_input_field(name2)\n",
        "\n",
        "        name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "            )\n",
        "        )\n",
        "        name2.send_keys(input2_value)\n",
        "\n",
        "\n",
        "\n",
        "        # opponent 1 flag\n",
        "        file_input_opponent1 = WebDriverWait(browser, 10).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH, \"//label[contains(text(), 'Opponent #1 Flag')]/following-sibling::input[@type='file']\")\n",
        "            )\n",
        "        )\n",
        "        file_path_opponent1 = os.path.join(logos_base_path, f\"{input1_value}.png\")\n",
        "        file_input_opponent1.send_keys(file_path_opponent1)\n",
        "\n",
        "        # opponent 2 flag\n",
        "        file_input_opponent2 = WebDriverWait(browser, 10).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH, \"//label[contains(text(), 'Opponent #2 Flag')]/following-sibling::input[@type='file']\")\n",
        "            )\n",
        "        )\n",
        "        file_path_opponent2 = os.path.join(logos_base_path, f\"{input2_value}.png\")\n",
        "        file_input_opponent2.send_keys(file_path_opponent2)\n",
        "\n",
        "        # delete event long\n",
        "\n",
        "        event_long = WebDriverWait(browser, 10, 0.2).until(\n",
        "            EC.element_to_be_clickable(\n",
        "                (By.CSS_SELECTOR, \"input[value='Event Long']\")\n",
        "            )\n",
        "        )\n",
        "        clear_input_field(event_long)\n",
        "        event_long.send_keys(\" \")\n",
        "\n",
        "        # round\n",
        "\n",
        "        round_textarea = WebDriverWait(browser, 10).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//label[contains(text(), 'Round')]/following-sibling::textarea\"))\n",
        "        )\n",
        "        clear_input_field(round_textarea)\n",
        "        round_textarea.send_keys(f\"{round_value}\")\n",
        "\n",
        "        # date (e.g Nov 6)\n",
        "        # Convert the string to a datetime object\n",
        "        datetime_obj = datetime.strptime(datetime_value, '%d/%m/%Y %H:%M')\n",
        "\n",
        "\n",
        "        if postmatch_logo_card:\n",
        "          date_input = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.XPATH, \"//input[@placeholder='competition date']\")\n",
        "              )\n",
        "          )\n",
        "          date_input = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='competition date']\"))\n",
        "          )\n",
        "          clear_input_field(date_input)\n",
        "          desired_date = datetime_obj.strftime('%b %-d')\n",
        "          date_input.send_keys(desired_date)\n",
        "\n",
        "\n",
        "        if prematch_logo_card:\n",
        "            # select kick off\n",
        "\n",
        "            select3 = WebDriverWait(browser, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, \"//label[contains(text(), 'Live Time Start Text')]/following-sibling::select\"))\n",
        "            )\n",
        "\n",
        "            select_object = Select(select3)\n",
        "            select_object.select_by_visible_text('Kick Off')\n",
        "\n",
        "\n",
        "            #time\n",
        "            time_input = browser.find_element(By.CSS_SELECTOR, \"input[type='time']\")\n",
        "\n",
        "\n",
        "            # Clear the field and set the new time\n",
        "            clear_input_field(time_input)\n",
        "\n",
        "            time_input.send_keys(time_value)\n",
        "            timezone = 'AEDT'  # @param [\"AEDT\", \"AEST\"]\n",
        "\n",
        "            #aedt\n",
        "            aedt_button = WebDriverWait(browser, 2, 0.2).until(\n",
        "                EC.element_to_be_clickable((By.ID, f'tz{timezone}'))\n",
        "            )\n",
        "            browser.execute_script(\"arguments[0].click();\", aedt_button)\n",
        "\n",
        "\n",
        "        if prematch_logo_card or postmatch_logo_card:\n",
        "            # comp - flag\n",
        "\n",
        "            # select4 = WebDriverWait(browser, 2, 0.2).until(\n",
        "            #     EC.presence_of_element_located(\n",
        "            #         (By.ID, \"select-special-carousel-logo-id\")\n",
        "            #     )\n",
        "            # )\n",
        "            # select4 = Select(select4)\n",
        "            # select4.select_by_visible_text('RUGBY: Hospital Cup')\n",
        "\n",
        "          select4_input = WebDriverWait(browser, 10).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH, \"//label[contains(text(), 'Carousel Logo')]/following-sibling::input[@type='file']\")\n",
        "              )\n",
        "          )\n",
        "          # Mapping the competition names to file paths\n",
        "          file_paths = {\n",
        "              \"Hospital Cup\": '/content/Flags/Hospital Cup.png',\n",
        "              \"Shute Shield\": '/content/Flags/Shute Shield.png',\n",
        "              \"Oceania Rugby\": '/content/Flags/Oceania Rugby.png',\n",
        "\n",
        "          }\n",
        "          select4_path = file_paths[rugby]\n",
        "          select4_input.send_keys(select4_path)\n",
        "\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "        # downloading\n",
        "\n",
        "        try:\n",
        "            # Wait for the button to be clickable by both class and text, with a timeout of 10 seconds\n",
        "            save_as_zip_button = WebDriverWait(browser, 10).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-warning') and contains(text(), 'Save as .zip')]\"))\n",
        "            )\n",
        "            time.sleep(5)\n",
        "\n",
        "            # Instead of clicking the button with Selenium's click function, we use JavaScript to click\n",
        "            browser.execute_script(\"arguments[0].click();\", save_as_zip_button)\n",
        "            print(\"Button clicked successfully via JavaScript.\")\n",
        "        except TimeoutException:\n",
        "            print(\"Button was not found within the given time.\")\n",
        "        except NoSuchElementException:\n",
        "            print(\"Button could not be found.\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "        download_directory = download_default_directory\n",
        "        try:\n",
        "            downloaded_file = wait_for_download_complete(download_directory)\n",
        "            print(f\"Download complete: {downloaded_file}\")\n",
        "        except Exception as e:\n",
        "            print(str(e))\n",
        "\n",
        "        zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')], key=lambda f: os.path.getctime(os.path.join(download_directory, f)), reverse=True)\n",
        "\n",
        "        if zip_files:\n",
        "            zip_file_name = zip_files[0]\n",
        "            zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "            with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                zip_ref.extractall(download_directory)\n",
        "                extracted_files = zip_ref.namelist()\n",
        "\n",
        "            if extracted_files:\n",
        "                new_singles_folder_path = os.path.join(download_directory, f\"{input1_value} v {input2_value} {round_value}\")\n",
        "                if not os.path.exists(new_singles_folder_path):\n",
        "                    os.mkdir(new_singles_folder_path)\n",
        "\n",
        "                print(f\"Moving files to {new_singles_folder_path}\")\n",
        "\n",
        "                for file in extracted_files:\n",
        "                    original_file_path = os.path.join(download_directory, file)\n",
        "                    new_file_path = os.path.join(new_singles_folder_path, file)\n",
        "                    # print(f\"Moving {original_file_path} to {new_file_path}\")\n",
        "                    shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "                subprocess.run([\"open\", \"-R\", new_singles_folder_path])\n",
        "\n",
        "            else:\n",
        "                print(\"No files found in the zip.\")\n",
        "        else:\n",
        "            print(\"No zip files found in the download directory.\")\n",
        "\n",
        "        os.remove(zip_file_path)\n",
        "\n",
        "browser.quit()"
      ],
      "metadata": {
        "id": "EuqpCkqaX-nq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading\n",
        "\n",
        "folder_path = folder_name  # replace with your folder path\n",
        "zip_file = f'{folder_name}.zip'  # name of the resulting zip file\n",
        "\n",
        "# Compress the folder\n",
        "os.system(f'zip -r {zip_file} {folder_path}')\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5upNCmadX-ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Deleting things\n",
        "\n",
        "import shutil\n",
        "\n",
        "dir_path = 'Prepromotes'\n",
        "\n",
        "# Remove the directory along with all its contents\n",
        "shutil.rmtree(dir_path)\n"
      ],
      "metadata": {
        "id": "dPsXWa46X-ns",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Motorsport Preimages**"
      ],
      "metadata": {
        "id": "8VnSBadv4IqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installing Selenium\n",
        "\n",
        "# Set up for running selenium in Google Colab\n",
        "## You don't need to run this code if you do it in Jupyter notebook, or other local Python setting\n",
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "CHROME_DRIVER_VERSION=`curl -sS chromedriver.storage.googleapis.com/LATEST_RELEASE`\n",
        "wget -N https://chromedriver.storage.googleapis.com/$CHROME_DRIVER_VERSION/chromedriver_linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver_linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver\n",
        "mv /tmp/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium\n",
        "pip install webdriver-manager"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vmlz3U9P6VKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading Logos Folder from Dropbox\n",
        "\n",
        "!wget -O Logos.zip \"https://www.dropbox.com/scl/fo/17v400uls31pak9vm2rqp/h?rlkey=socex8uazv4fy62xnq64nmosk&dl=0\"\n",
        "\n",
        "!mkdir -p Logos\n",
        "!unzip Logos.zip -d Logos\n",
        "!rm Logos.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7nKbZW0b6SVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Prepromotes**\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException, ElementClickInterceptedException\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.service_account import Credentials\n",
        "\n",
        "folder_name = 'Prepromotes'\n",
        "os.makedirs(folder_name, exist_ok=True)\n",
        "download_default_directory = f'/content/{folder_name}'\n",
        "\n",
        "#logos image input\n",
        "logos_base_path = '/content/Flags'\n",
        "\n",
        "# Google Sheets API setup\n",
        "creds = Credentials.from_service_account_file('/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0')\n",
        "service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "# Your Google Sheet ID and the range of cells to access\n",
        "SPREADSHEET_ID = '1I966sTVn6_KZBqoK1AF2eaPnDhypBel0l9zX0MlsSBg' #@param {type:\"string\"}\n",
        "RANGE_NAME = 'Tilebot!A1:M200'\n",
        "\n",
        "motorsport = 'WEC (Lower Strap)' # @param [\"Indycar 2024\", \"WEC (Lower Strap)\"]\n",
        "\n",
        "\n",
        "live_and_upcoming = True # @param {type:\"boolean\"}\n",
        "prematch_logo_card = True # @param {type:\"boolean\"}\n",
        "postmatch_logo_card = True # @param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Set up headless Chrome options\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_experimental_option(\"prefs\", {\n",
        "  \"download.default_directory\": f'/content/{folder_name}',\n",
        "  \"download.prompt_for_download\": False,\n",
        "  \"download.directory_upgrade\": True,\n",
        "  \"safebrowsing.enabled\": True\n",
        "})\n",
        "\n",
        "# Call the Sheets API to read data\n",
        "sheet_service = service.spreadsheets()\n",
        "result = sheet_service.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
        "values = result.get('values', [])\n",
        "\n",
        "# Function to clear input field\n",
        "def clear_input_field(element):\n",
        "    # Clear using Selenium's clear method\n",
        "    element.clear()\n",
        "    # If the element is not cleared, use JavaScript to clear it\n",
        "    browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "    # Check and retry if the input is not cleared\n",
        "    for i in range(3):\n",
        "        if element.get_attribute('value'):\n",
        "            element.clear()\n",
        "            browser.execute_script(\"arguments[0].value = '';\", element)\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "def wait_for_download_complete(download_directory, timeout=300):\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        # Find the most recent zip file in the directory\n",
        "        zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')],\n",
        "                           key=lambda f: os.path.getctime(os.path.join(download_directory, f)),\n",
        "                           reverse=True)\n",
        "\n",
        "        if zip_files:\n",
        "            latest_zip = os.path.join(download_directory, zip_files[0])\n",
        "            initial_size = os.path.getsize(latest_zip)\n",
        "\n",
        "            # Wait for a short period to check if the file is still being written to\n",
        "            time.sleep(1)\n",
        "            if os.path.getsize(latest_zip) == initial_size:\n",
        "                # If file size hasn't changed, assume download is complete\n",
        "                return latest_zip\n",
        "\n",
        "        # Check for timeout\n",
        "        if (time.time() - start_time) > timeout:\n",
        "            raise Exception(\"Timeout: File download did not complete within the specified time.\")\n",
        "\n",
        "        time.sleep(1)  # Check every 1 second\n",
        "\n",
        "# Create a browser instance with headless Chrome\n",
        "browser = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
        "\n",
        "# Process and iterate over Google Sheets data\n",
        "if not values:\n",
        "    print('No data found.')\n",
        "else:\n",
        "    for row in values:\n",
        "        # Ensure row has enough elements\n",
        "        row += [None] * (5 - len(row))\n",
        "\n",
        "        # Unpack the row into variables\n",
        "        no_value, datetime_value, input1_value, input2_value, round_value = row\n",
        "\n",
        "        if input1_value is None:  # Check for end of data\n",
        "            break\n",
        "\n",
        "        browser.get('https://thelivecms.prod.streamco.cloud/tile-creator/')\n",
        "            # live & upcoming\n",
        "\n",
        "        if live_and_upcoming:\n",
        "          live = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Live & Upcoming')]\")\n",
        "              )\n",
        "          )\n",
        "          live.click();\n",
        "\n",
        "          # home & away\n",
        "          home = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Motorsport')]\")\n",
        "              )\n",
        "          )\n",
        "          home.click()\n",
        "\n",
        "\n",
        "          # select sport + competition\n",
        "\n",
        "          select1 = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.ID, \"select-sport-type-id\")\n",
        "              )\n",
        "          )\n",
        "          select1 = Select(select1)\n",
        "          select1.select_by_visible_text('Motorsport')\n",
        "\n",
        "          select2 = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.ID, \"select-competition-id\")\n",
        "              )\n",
        "          )\n",
        "          select2 = Select(select2)\n",
        "\n",
        "          selection_text = f'MOTORSPORT: {motorsport}'\n",
        "          select2.select_by_visible_text(selection_text)\n",
        "\n",
        "          # name 1\n",
        "\n",
        "          name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='Monaco']\")\n",
        "              )\n",
        "          )\n",
        "          clear_input_field(name1)\n",
        "          time.sleep(2)\n",
        "\n",
        "          name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='Monaco']\")\n",
        "              )\n",
        "          )\n",
        "          name1.send_keys(input1_value)\n",
        "\n",
        "          # name 2\n",
        "          name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='Daily highlights 2']\")\n",
        "              )\n",
        "          )\n",
        "          clear_input_field(name2)\n",
        "\n",
        "          name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='Daily highlights 2']\")\n",
        "              )\n",
        "          )\n",
        "          name2.send_keys(input2_value)\n",
        "\n",
        "          round_textarea = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable((By.XPATH, \"//label[contains(text(), 'Round')]/following-sibling::textarea\"))\n",
        "          )\n",
        "          clear_input_field(round_textarea)\n",
        "          round_textarea.send_keys(\" \")\n",
        "\n",
        "\n",
        "          try:\n",
        "              # Wait for the button to be clickable by both class and text, with a timeout of 10 seconds\n",
        "              save_as_zip_button = WebDriverWait(browser, 10).until(\n",
        "                  EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-warning') and contains(text(), 'Save as .zip')]\"))\n",
        "              )\n",
        "              time.sleep(5)\n",
        "\n",
        "              # Instead of clicking the button with Selenium's click function, we use JavaScript to click\n",
        "              browser.execute_script(\"arguments[0].click();\", save_as_zip_button)\n",
        "              print(\"Button clicked successfully via JavaScript.\")\n",
        "          except TimeoutException:\n",
        "              print(\"Button was not found within the given time.\")\n",
        "          except NoSuchElementException:\n",
        "              print(\"Button could not be found.\")\n",
        "          except Exception as e:\n",
        "              print(f\"An error occurred: {e}\")\n",
        "          download_directory = download_default_directory\n",
        "          try:\n",
        "              downloaded_file = wait_for_download_complete(download_directory)\n",
        "              print(f\"Download complete: {downloaded_file}\")\n",
        "          except Exception as e:\n",
        "              print(str(e))\n",
        "\n",
        "          zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')], key=lambda f: os.path.getctime(os.path.join(download_directory, f)), reverse=True)\n",
        "\n",
        "          if zip_files:\n",
        "              zip_file_name = zip_files[0]\n",
        "              zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "              with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                  zip_ref.extractall(download_directory)\n",
        "                  extracted_files = zip_ref.namelist()\n",
        "\n",
        "              if extracted_files:\n",
        "                  new_singles_folder_path = os.path.join(download_directory, f\"{input2_value}: {input1_value}\")\n",
        "                  if not os.path.exists(new_singles_folder_path):\n",
        "                      os.mkdir(new_singles_folder_path)\n",
        "\n",
        "                  print(f\"Moving files to {new_singles_folder_path}\")\n",
        "\n",
        "                  for file in extracted_files:\n",
        "                      original_file_path = os.path.join(download_directory, file)\n",
        "                      new_file_path = os.path.join(new_singles_folder_path, file)\n",
        "                      # print(f\"Moving {original_file_path} to {new_file_path}\")\n",
        "                      shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "                  subprocess.run([\"open\", \"-R\", new_singles_folder_path])\n",
        "\n",
        "              else:\n",
        "                  print(\"No files found in the zip.\")\n",
        "          else:\n",
        "              print(\"No zip files found in the download directory.\")\n",
        "\n",
        "          os.remove(zip_file_path)\n",
        "\n",
        "        time.sleep(2)\n",
        "\n",
        "        live = WebDriverWait(browser, 2, 0.2).until(\n",
        "            EC.presence_of_element_located(\n",
        "                (By.XPATH,  \"//*[contains(text(), 'Live & Upcoming')]\")\n",
        "            )\n",
        "        )\n",
        "        time.sleep(1)\n",
        "        live.click();\n",
        "        time.sleep(0.5)\n",
        "\n",
        "        if prematch_logo_card or postmatch_logo_card:\n",
        "          # logo cards\n",
        "          logo = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.presence_of_element_located(\n",
        "                  (By.XPATH,  \"//*[contains(text(), 'Logo Cards')]\")\n",
        "              )\n",
        "          )\n",
        "          logo.click();\n",
        "          # prematch logo card\n",
        "          if prematch_logo_card:\n",
        "            pre = WebDriverWait(browser, 2, 0.2).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH,  \"//*[contains(text(), 'Logo Card Prematch')]\")\n",
        "                )\n",
        "            )\n",
        "            pre.click()\n",
        "          # postmatch logo card\n",
        "          if postmatch_logo_card:\n",
        "            post = WebDriverWait(browser, 2, 0.2).until(\n",
        "                EC.presence_of_element_located(\n",
        "                    (By.XPATH,  \"//*[contains(text(), 'Logo Card Postmatch')]\")\n",
        "                )\n",
        "            )\n",
        "            post.click()\n",
        "\n",
        "          # name 1\n",
        "\n",
        "          name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "              )\n",
        "          )\n",
        "          clear_input_field(name1)\n",
        "          time.sleep(2)\n",
        "\n",
        "          name1 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='home1']\")\n",
        "              )\n",
        "          )\n",
        "          name1.send_keys(input1_value)\n",
        "\n",
        "          # name 2\n",
        "          name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "              )\n",
        "          )\n",
        "          clear_input_field(name2)\n",
        "\n",
        "          name2 = WebDriverWait(browser, 10, 0.2).until(\n",
        "              EC.element_to_be_clickable(\n",
        "                  (By.CSS_SELECTOR, \"input[value='away1']\")\n",
        "              )\n",
        "          )\n",
        "          name2.send_keys(input2_value)\n",
        "\n",
        "          # round\n",
        "          round_textarea = WebDriverWait(browser, 10).until(\n",
        "              EC.element_to_be_clickable((By.XPATH, \"//label[contains(text(), 'Round')]/following-sibling::textarea\"))\n",
        "          )\n",
        "          clear_input_field(round_textarea)\n",
        "          round_textarea.send_keys(f\"{round_value}\")\n",
        "\n",
        "          # select kick off\n",
        "\n",
        "          select3 = WebDriverWait(browser, 10).until(\n",
        "              EC.presence_of_element_located((By.XPATH, \"//label[contains(text(), 'Live Time Start Text')]/following-sibling::select\"))\n",
        "          )\n",
        "\n",
        "          select_object = Select(select3)\n",
        "          select_object.select_by_visible_text('Starts')\n",
        "\n",
        "          # date (e.g Nov 6)\n",
        "          # Convert the string to a datetime object\n",
        "          datetime_obj = datetime.strptime(datetime_value, '%d/%m/%Y %H:%M')\n",
        "\n",
        "          #time\n",
        "          time_input = browser.find_element(By.CSS_SELECTOR, \"input[type='time']\")\n",
        "\n",
        "          # Clear the field and set the new time\n",
        "          clear_input_field(time_input)\n",
        "\n",
        "          time_value = datetime_obj.strftime('%H:%M%p').lower()\n",
        "\n",
        "          time_input.send_keys(time_value)\n",
        "          timezone = 'AEDT'  # @param [\"AEDT\", \"AEST\"]\n",
        "\n",
        "          #aedt\n",
        "          aedt_button = WebDriverWait(browser, 2, 0.2).until(\n",
        "              EC.element_to_be_clickable((By.ID, f'tz{timezone}'))\n",
        "          )\n",
        "          browser.execute_script(\"arguments[0].click();\", aedt_button)\n",
        "\n",
        "          if prematch_logo_card or postmatch_logo_card:\n",
        "              date_input = WebDriverWait(browser, 10).until(\n",
        "                  EC.element_to_be_clickable(\n",
        "                      (By.XPATH, \"//input[@placeholder='competition date']\")\n",
        "                  )\n",
        "              )\n",
        "              date_input = WebDriverWait(browser, 10).until(\n",
        "                  EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='competition date']\"))\n",
        "              )\n",
        "              clear_input_field(date_input)\n",
        "              desired_date = datetime_obj.strftime('%b %-d')\n",
        "              date_input.send_keys(desired_date)\n",
        "\n",
        "              # comp - flag\n",
        "\n",
        "              # select4 = WebDriverWait(browser, 2, 0.2).until(\n",
        "              #     EC.presence_of_element_located(\n",
        "              #         (By.ID, \"select-special-carousel-logo-id\")\n",
        "              #     )\n",
        "              # )\n",
        "              # select4 = Select(select4)\n",
        "              # select4.select_by_visible_text('RUGBY: Hospital Cup')\n",
        "\n",
        "              if motorsport == 'WEC (Lower Strap)'\n",
        "                comp - flag\n",
        "\n",
        "                select4 = WebDriverWait(browser, 2, 0.2).until(\n",
        "                    EC.presence_of_element_located(\n",
        "                        (By.ID, \"select-special-carousel-logo-id\")\n",
        "                    )\n",
        "                )\n",
        "                select4 = Select(select4)\n",
        "                select4.select_by_visible_text('MOTORSPORT: WEC (Endurance)')\n",
        "              else:\n",
        "                select4_input = WebDriverWait(browser, 10).until(\n",
        "                    EC.presence_of_element_located(\n",
        "                        (By.XPATH, \"//label[contains(text(), 'Carousel Logo')]/following-sibling::input[@type='file']\")\n",
        "                    )\n",
        "                )\n",
        "                # Mapping the competition names to file paths\n",
        "                file_paths = {\n",
        "                    \"Indycar 2024\": '/content/Logos/Indycar.png',\n",
        "\n",
        "                }\n",
        "                select4_path = file_paths[motorsport]\n",
        "                select4_input.send_keys(select4_path)\n",
        "\n",
        "\n",
        "              browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "              time.sleep(2)\n",
        "\n",
        "\n",
        "              fourplayers_checkbox = WebDriverWait(browser, 2, 0.2).until(\n",
        "                  EC.element_to_be_clickable(\n",
        "                      (By.XPATH,  \"//label[text()='Show V']/preceding-sibling::input\")\n",
        "                  )\n",
        "              )\n",
        "              fourplayers_checkbox.click()\n",
        "\n",
        "              crazyplayers_checkbox = WebDriverWait(browser, 2, 0.2).until(\n",
        "                  EC.element_to_be_clickable(\n",
        "                      (By.XPATH,  \"//label[text()='Show Team Logos']/preceding-sibling::input\")\n",
        "                  )\n",
        "              )\n",
        "              crazyplayers_checkbox.click()\n",
        "\n",
        "              time.sleep(2)\n",
        "\n",
        "              # downloading\n",
        "              try:\n",
        "                  # Wait for the button to be clickable by both class and text, with a timeout of 10 seconds\n",
        "                  save_as_zip_button = WebDriverWait(browser, 10).until(\n",
        "                      EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'btn-warning') and contains(text(), 'Save as .zip')]\"))\n",
        "                  )\n",
        "                  time.sleep(5)\n",
        "\n",
        "                  # Instead of clicking the button with Selenium's click function, we use JavaScript to click\n",
        "                  browser.execute_script(\"arguments[0].click();\", save_as_zip_button)\n",
        "                  print(\"Button clicked successfully via JavaScript.\")\n",
        "              except TimeoutException:\n",
        "                  print(\"Button was not found within the given time.\")\n",
        "              except NoSuchElementException:\n",
        "                  print(\"Button could not be found.\")\n",
        "              except Exception as e:\n",
        "                  print(f\"An error occurred: {e}\")\n",
        "              download_directory = download_default_directory\n",
        "              try:\n",
        "                  downloaded_file = wait_for_download_complete(download_directory)\n",
        "                  print(f\"Download complete: {downloaded_file}\")\n",
        "              except Exception as e:\n",
        "                  print(str(e))\n",
        "\n",
        "              new_singles_folder_path = os.path.join(download_directory, f\"{input2_value}: {input1_value}\")\n",
        "              folder_path = new_singles_folder_path\n",
        "\n",
        "              zip_files = sorted([f for f in os.listdir(download_directory) if f.endswith('.zip')], key=lambda f: os.path.getctime(os.path.join(download_directory, f)), reverse=True)\n",
        "              if zip_files:\n",
        "                zip_file_name = zip_files[0]\n",
        "                zip_file_path = os.path.join(download_directory, zip_file_name)\n",
        "\n",
        "                # Verify the zip file before attempting to extract\n",
        "                if os.path.isfile(zip_file_path) and os.path.getsize(zip_file_path) > 0:\n",
        "                    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "                        try:\n",
        "                            zip_ref.extractall(download_directory)\n",
        "                            extracted_files = zip_ref.namelist()\n",
        "                            print(f\"Extracted files: {extracted_files}\")\n",
        "                        except zipfile.BadZipFile:\n",
        "                            print(f\"Failed to extract {zip_file_path}: The file may be corrupted.\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"An unexpected error occurred while extracting {zip_file_path}: {e}\")\n",
        "                else:\n",
        "                  print(f\"The zip file {zip_file_path} does not exist or is empty.\")\n",
        "              # Move files directly to the existing folder\n",
        "              for file in extracted_files:\n",
        "                  original_file_path = os.path.join(download_directory, file)\n",
        "                  new_file_path = os.path.join(folder_path, file)  # Use folder_path directly\n",
        "                  shutil.move(original_file_path, new_file_path)\n",
        "\n",
        "              os.remove(zip_file_path)\n",
        "\n",
        "browser.quit()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "twgi6mo84K5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloading\n",
        "\n",
        "folder_path = folder_name  # replace with your folder path\n",
        "zip_file = f'{folder_name}.zip'  # name of the resulting zip file\n",
        "\n",
        "# Compress the folder\n",
        "os.system(f'zip -r {zip_file} {folder_path}')\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lK45_ZcdEkp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Deleting things\n",
        "\n",
        "import shutil\n",
        "\n",
        "dir_path = 'Prepromotes'\n",
        "\n",
        "# Remove the directory along with all its contents\n",
        "shutil.rmtree(dir_path)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XOG3NJjLCwvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making shells\n"
      ],
      "metadata": {
        "id": "x4pcGBds_sTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Invoking Variables\n",
        "\n",
        "credentials_file ='/content/tile-bot-405312-8bb4e65cbe47.json?rlkey=izjxkv7pygdtjkj0r494z16zg&dl=0'\n",
        "sheet_id = '1uL3RbbuTviZHVr2tobMOz3aotp0SJzK4YkO-MlJYN4w'  #@param {type:\"string\"}\n",
        "template_sheet_id = '1uL3RbbuTviZHVr2tobMOz3aotp0SJzK4YkO-MlJYN4w' #@param {type:\"string\"}\n",
        "template_worksheet_name = 'Template'\n",
        "sheet_range = 'A1:AK1000' #@param {type:\"string\"}\n",
        "dest_worksheet_name = 'Shells'\n",
        "source_worksheet_name = 'Tilebot'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lPODGcX-_5mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setting up initial Day from template\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "\n",
        "def copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the source and destination Google Sheets\n",
        "    try:\n",
        "        source_sheet = client.open_by_key(template_sheet_id)\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheets: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if the destination worksheet exists, create if not\n",
        "    try:\n",
        "        dest_worksheet = None\n",
        "        try:\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "        except gspread.WorksheetNotFound:\n",
        "            # Create a new worksheet\n",
        "            dest_sheet.add_worksheet(title=dest_worksheet_name, rows=\"1000\", cols=\"26\")  # Adjust rows and columns as needed\n",
        "            dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "\n",
        "        source_worksheet = source_sheet.worksheet(template_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error accessing or creating worksheets: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Get the detailed data from the source sheet\n",
        "        source_range = f'{source_worksheet.title}!{sheet_range}'\n",
        "        request = service.spreadsheets().get(spreadsheetId=template_sheet_id, ranges=[source_range], includeGridData=True)\n",
        "        source_data = request.execute()\n",
        "\n",
        "        # Extract data for updating the destination sheet\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        data = []\n",
        "        for row in rows:\n",
        "            row_data = []\n",
        "            for cell in row.get('values', []):\n",
        "                # Handle different types of values including formulas\n",
        "                if 'userEnteredValue' in cell:\n",
        "                    cell_value = cell['userEnteredValue']\n",
        "                    if 'formulaValue' in cell_value:\n",
        "                        row_data.append(cell_value['formulaValue'])\n",
        "                    elif 'stringValue' in cell_value:\n",
        "                        row_data.append(cell_value['stringValue'])\n",
        "                    elif 'numberValue' in cell_value:\n",
        "                        row_data.append(cell_value['numberValue'])\n",
        "                    elif 'boolValue' in cell_value:\n",
        "                        row_data.append(cell_value['boolValue'])\n",
        "                    else:\n",
        "                        row_data.append('')\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            data.append(row_data)\n",
        "\n",
        "        # Extract data validation rules\n",
        "        validation_rules = []\n",
        "        rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "        for i, row in enumerate(rows):\n",
        "            for j, cell in enumerate(row.get('values', [])):\n",
        "                if 'dataValidation' in cell:\n",
        "                    rule = cell['dataValidation']\n",
        "                    validation_rules.append({\n",
        "                        'range': {\n",
        "                            'sheetId': dest_worksheet.id,\n",
        "                            'startRowIndex': i,\n",
        "                            'endRowIndex': i + 1,\n",
        "                            'startColumnIndex': j,\n",
        "                            'endColumnIndex': j + 1\n",
        "                        },\n",
        "                        'rule': rule\n",
        "                    })\n",
        "\n",
        "        # Write values and formulas to the destination sheet\n",
        "        dest_range = f'{dest_worksheet.title}!{sheet_range}'\n",
        "        body = {'values': data}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Apply data validation rules to the destination sheet\n",
        "        if validation_rules:\n",
        "            requests = [{'setDataValidation': {'range': rule['range'], 'rule': rule['rule']}} for rule in validation_rules]\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': requests}).execute()\n",
        "\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': source_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Assuming 26 columns (A to Z)\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 0,\n",
        "                        'endRowIndex': len(rows),\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        print(f\"Data, formulas, formatting, and data validation rules copied successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during data and format copying: {e}\")\n",
        "\n",
        "copy_sheet_data_with_full_formatting(template_sheet_id, template_worksheet_name, sheet_id, dest_worksheet_name, credentials_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "A8nJBm9W_-1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copying over from match template based on amount of matches\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "import re\n",
        "import time\n",
        "\n",
        "\n",
        "# Example usage\n",
        "def adjust_formula(formula, row_offset, current_row, reference_row, same_row_columns, section_size=5):\n",
        "    \"\"\"\n",
        "    Adjust the row references in a formula by a specific offset.\n",
        "    For specific rows and columns, the formulas will reference different rows based on the logic provided.\n",
        "    \"\"\"\n",
        "    cell_ref_regex = r'([A-Z\\$]+)(\\d+)'\n",
        "\n",
        "    def adjust_match(match):\n",
        "        col_ref = match.group(1)  # Column reference\n",
        "        row_ref = int(match.group(2))  # Row reference\n",
        "        if '$' not in col_ref:  # Skip absolute row references\n",
        "            if col_ref in same_row_columns and (current_row - reference_row) % section_size == 0:\n",
        "                # For specified columns in the first row of each section, reference the same row\n",
        "                adjusted_row_ref = current_row\n",
        "            elif col_ref in same_row_columns:\n",
        "                # For specified columns in other rows, reference the first row of the section\n",
        "                adjusted_row_ref = current_row - ((current_row - reference_row) % section_size)\n",
        "            else:\n",
        "                # For other columns, adjust normally\n",
        "                adjusted_row_ref = row_ref + row_offset\n",
        "            return f'{col_ref}{adjusted_row_ref}'\n",
        "        else:\n",
        "            return f'{col_ref}{row_ref}'\n",
        "\n",
        "    adjusted_formula = re.sub(cell_ref_regex, adjust_match, formula)\n",
        "    return adjusted_formula\n",
        "\n",
        "def replicate_formatting(sheet_id, dest_worksheet_name, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Build the Google Sheets API service\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        dest_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the range to copy (rows 8-11)\n",
        "    copy_range = 'A8:AK11'\n",
        "\n",
        "    # Determine the number of rows to replicate based on 'Data 1' sheet\n",
        "    data_sheet = client.open_by_key(sheet_id).worksheet(source_worksheet_name)\n",
        "    data_rows = len(data_sheet.get_all_values())\n",
        "    rows_to_replicate = data_rows - 3\n",
        "\n",
        "    # Get the detailed data from the range to copy, including data validation rules\n",
        "    request = service.spreadsheets().get(spreadsheetId=sheet_id, ranges=[f'{dest_worksheet.title}!{copy_range}'], includeGridData=True)\n",
        "    source_data = request.execute()\n",
        "\n",
        "    # Extract data, formulas, formats, and data validation rules for updating the destination sheet\n",
        "    source_rows = source_data['sheets'][0]['data'][0].get('rowData', [])\n",
        "    source_data_list = []\n",
        "    data_validation_rules = []\n",
        "    for row_index, row in enumerate(source_rows):\n",
        "        row_data = []\n",
        "        row_rules = []\n",
        "        for cell_index, cell in enumerate(row.get('values', [])):\n",
        "            # Data extraction\n",
        "            if 'userEnteredValue' in cell:\n",
        "                cell_value = cell['userEnteredValue']\n",
        "                if 'formulaValue' in cell_value:\n",
        "                    row_data.append(cell_value['formulaValue'])\n",
        "                elif 'stringValue' in cell_value:\n",
        "                    row_data.append(cell_value['stringValue'])\n",
        "                elif 'numberValue' in cell_value:\n",
        "                    row_data.append(cell_value['numberValue'])\n",
        "                elif 'boolValue' in cell_value:\n",
        "                    row_data.append(cell_value['boolValue'])\n",
        "                else:\n",
        "                    row_data.append('')\n",
        "            else:\n",
        "                row_data.append('')\n",
        "\n",
        "            # Data validation rule extraction\n",
        "            if 'dataValidation' in cell:\n",
        "                rule = cell['dataValidation']\n",
        "                row_rules.append((row_index, cell_index, rule))\n",
        "        source_data_list.append(row_data)\n",
        "        data_validation_rules.extend(row_rules)\n",
        "\n",
        "    # Replicate the formatting, data, and data validation rules with gaps\n",
        "    original_row_count = 4  # Number of rows in the source range (8-11)\n",
        "    start_row = 12  # Start copying from row 13, leaving a gap after row 11\n",
        "    same_row_columns = {'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','AA','AB','AC','AE','AG','AH','AI','AJ', 'AK'}  # Columns that should always reference the same row\n",
        "\n",
        "    for i in range(rows_to_replicate):\n",
        "        row_offset = (original_row_count + 1) * i  # Calculate the offset for this replication\n",
        "        reference_row = start_row + 1  # The first row of the current section\n",
        "\n",
        "        # Data and formula adjustment\n",
        "        adjusted_data_list = []\n",
        "        for row_index, row in enumerate(source_data_list):\n",
        "            current_row = start_row + row_index + 1  # Calculate the current row\n",
        "            adjusted_row = []\n",
        "            for cell in row:\n",
        "                if isinstance(cell, str) and cell.startswith('='):  # Check if it's a formula\n",
        "                    adjusted_row.append(adjust_formula(cell, row_offset, current_row, reference_row, same_row_columns))\n",
        "                else:\n",
        "                    adjusted_row.append(cell)\n",
        "            adjusted_data_list.append(adjusted_row)\n",
        "\n",
        "        # Update values and formulas\n",
        "        dest_range = f'{dest_worksheet.title}!A{start_row + 1}:AK{start_row + 4}'\n",
        "        body = {'values': adjusted_data_list}\n",
        "        service.spreadsheets().values().update(\n",
        "            spreadsheetId=sheet_id, range=dest_range,\n",
        "            valueInputOption='USER_ENTERED', body=body).execute()\n",
        "\n",
        "        # Copy formatting\n",
        "        format_requests = {\n",
        "            'requests': [{\n",
        "                'copyPaste': {\n",
        "                    'source': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': 7,\n",
        "                        'endRowIndex': 11,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,  # Including column AK\n",
        "                    },\n",
        "                    'destination': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row,\n",
        "                        'endRowIndex': start_row + 4,\n",
        "                        'startColumnIndex': 0,\n",
        "                        'endColumnIndex': 37,\n",
        "                    },\n",
        "                    'pasteType': 'PASTE_FORMAT',\n",
        "                    'pasteOrientation': 'NORMAL'\n",
        "                }\n",
        "            }]\n",
        "        }\n",
        "        service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body=format_requests).execute()\n",
        "\n",
        "        # Apply data validation rules\n",
        "        for rule_index, (src_row, src_col, rule) in enumerate(data_validation_rules):\n",
        "            rule_request = {\n",
        "                'setDataValidation': {\n",
        "                    'range': {\n",
        "                        'sheetId': dest_worksheet.id,\n",
        "                        'startRowIndex': start_row + src_row,\n",
        "                        'endRowIndex': start_row + src_row + 1,\n",
        "                        'startColumnIndex': src_col,\n",
        "                        'endColumnIndex': src_col + 1,\n",
        "                    },\n",
        "                    'rule': rule\n",
        "                }\n",
        "            }\n",
        "            time.sleep(3.5)\n",
        "            service.spreadsheets().batchUpdate(spreadsheetId=sheet_id, body={'requests': [rule_request]}).execute()\n",
        "\n",
        "        # Update the starting row for the next replication\n",
        "        start_row += 5  # 4 rows of data plus 1 row gap\n",
        "\n",
        "    print(f\"Formats, data, and data validation rules replicated successfully for {rows_to_replicate} sections.\")\n",
        "\n",
        "# Call the function\n",
        "replicate_formatting(sheet_id, dest_worksheet_name, credentials_file)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qwUIIwnwABK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copying over match data from data sheet\n",
        "\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def transfer_data(sheet_id, credentials_file):\n",
        "    # Authenticate and create a client\n",
        "    scope = [\"https://www.googleapis.com/auth/spreadsheets\", \"https://www.googleapis.com/auth/drive\"]\n",
        "    creds = ServiceAccountCredentials.from_json_keyfile_name(credentials_file, scope)\n",
        "    client = gspread.authorize(creds)\n",
        "\n",
        "    # Open the destination Google Sheet\n",
        "    try:\n",
        "        dest_sheet = client.open_by_key(sheet_id)\n",
        "        data_worksheet = dest_sheet.worksheet(source_worksheet_name)\n",
        "        day_worksheet = dest_sheet.worksheet(dest_worksheet_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening sheet: {e}\")\n",
        "        return\n",
        "\n",
        "    # Define the columns to transfer and their destination columns\n",
        "    columns_to_transfer = {\n",
        "        1: 'AB',  # D2 onwards to AB3 onwards - time\n",
        "        # 2: 'AC',  # A2 onwards to AC3 onwards - player 1\n",
        "        # 3: 'AE',  # B2 onwards to AE3 onwards - player 2\n",
        "        # 4: 'AA',   # C2 onwards to Z3 onwards - round\n",
        "    }\n",
        "\n",
        "    for source_col, dest_col_prefix in columns_to_transfer.items():\n",
        "        # Get all values from the source column starting from row 2\n",
        "        values = data_worksheet.col_values(source_col)[1:]  # Skip the first row (title)\n",
        "\n",
        "        # Loop through the values\n",
        "        for i, value in enumerate(values, start=1):\n",
        "            # Calculate the destination row using the formula\n",
        "            dest_row = 3 + (i - 1) * 5\n",
        "\n",
        "            # Write the value to the calculated cell in 'Day 1'\n",
        "            time.sleep(2)\n",
        "            day_worksheet.update_acell(f'{dest_col_prefix}{dest_row}', value)\n",
        "        print(f\"Data from column {source_col} transferred to column {dest_col_prefix} for {len(values)} rows.\")\n",
        "\n",
        "# Call the function\n",
        "transfer_data(sheet_id, credentials_file)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Jc3Cg35aAFQo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xXa1uVJmUVGA",
        "SAQbS8ISj1Od",
        "sTO8tqbjgiow",
        "v8akBQlntQQR",
        "AuLGvpqjD8YV",
        "udQ4DxpooVhd",
        "SsbdofNAhHKM",
        "8dabaQ2hi3Sx",
        "r_qppE7uiHf5",
        "aSYxxHiXjMZ7",
        "f-i2Vzm5jMaB",
        "qRbJjLatjMaB",
        "aD4nwbMkkV7_",
        "L4F_uAjkkV8F",
        "EdiJRlkZkV8G",
        "xXc54Z0NGYdZ",
        "ypKS8R_OGJSk",
        "1H_ALTHvX-nb",
        "8VnSBadv4IqZ",
        "x4pcGBds_sTu"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOVYKPXOHqStDnPJITGvulr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}